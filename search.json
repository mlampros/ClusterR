[{"path":"https://mlampros.github.io/ClusterR/articles/the_clusterR_package.html","id":"gaussian-mixture-models-gmm","dir":"Articles","previous_headings":"","what":"Gaussian Mixture Models (GMM)","title":"Functionality of the ClusterR package","text":"Gaussian Mixture Models probabilistic model representing normally distributed subpopulations within overall population. Gaussian mixture model parameterized two types values, mixture component weights component means covariances (multivariate case). number components known, expectation maximization technique commonly used estimate mixture model’s parameters. GMM function ClusterR package R implementation Armadillo library class modeling data Gaussian Mixture Model (GMM), assumption diagonal covariance matrices. number function parameters can tuned, among others gaussian_comps, dist_mode (eucl_dist, maha_dist), seed_mode (static_subset, random_subset, static_spread, random_spread), km_iter em_iter (information parameters can found package documentation). ’ll illustrate GMM function using synthetic data dietary_survey_IBS,  GMM function, initially, returns centroids, covariance matrix ( row matrix represents diagonal covariance matrix), weights log-likelihoods gaussian component. , predict function takes GMM model returns probable clusters. addition previous mentioned functions, Optimal_Clusters_GMM can utilized estimate number clusters data using either AIC (Akaike information) BIC (Bayesian information) criterion,    case model selection, among specific number models, model lowest BIC preferred, true number clusters equal 2. Assuming true labels available, one use external_validation methods (rand_index, adjusted_rand_index, jaccard_index, fowlkes_Mallows_index, mirkin_metric, purity, entropy, nmi (normalized mutual information) var_info (variation information) validate output clusters,  summary_stats parameter set TRUE also returns specificity, sensitivity, precision, recall F-measure metrics.","code":"library(ClusterR)  data(dietary_survey_IBS)  dim(dietary_survey_IBS) ## [1] 400  43 X = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]   # data (excluding the response variable)  y = dietary_survey_IBS[, ncol(dietary_survey_IBS)]    # the response variable  dat = center_scale(X, mean_center = T, sd_scale = T)  # centering and scaling the data gmm = GMM(dat, 2, dist_mode = \"maha_dist\", seed_mode = \"random_subset\", km_iter = 10,           em_iter = 10, verbose = F)            # predict centroids, covariance matrix and weights pr = predict(gmm, newdata = dat) opt_gmm = Optimal_Clusters_GMM(dat, max_clusters = 10, criterion = \"BIC\",                                                                 dist_mode = \"maha_dist\", seed_mode = \"random_subset\",                                                                km_iter = 10, em_iter = 10, var_floor = 1e-10,                                                                 plot_data = T) res = external_validation(dietary_survey_IBS$class, pr$cluster_labels,                                                       method = \"adjusted_rand_index\", summary_stats = T)  res  ##   ## ----------------------------------------  ## purity                         : 1  ## entropy                        : 0  ## normalized mutual information  : 1  ## variation of information       : 0  ## ----------------------------------------  ## specificity                    : 1  ## sensitivity                    : 1  ## precision                      : 1  ## recall                         : 1  ## F-measure                      : 1  ## ----------------------------------------  ## accuracy OR rand-index         : 1  ## adjusted-rand-index            : 1  ## jaccard-index                  : 1  ## fowlkes-mallows-index          : 1  ## mirkin-metric                  : 0  ## ----------------------------------------"},{"path":"https://mlampros.github.io/ClusterR/articles/the_clusterR_package.html","id":"k-means","dir":"Articles","previous_headings":"","what":"k-means","title":"Functionality of the ClusterR package","text":"k-means clustering method vector quantization, originally signal processing, popular cluster analysis data mining. k-means clustering aims partition n observations k clusters observation belongs cluster nearest mean, serving prototype cluster. results partitioning data space Voronoi cells. common algorithm uses iterative refinement technique. Due ubiquity, often called k-means algorithm; also referred Lloyd’s algorithm, particularly computer science community. ClusterR package provides two different k-means functions, KMeans_arma, R implementation k-means armadillo library KMeans_rcpp uses RcppArmadillo package. functions come output results, however, return different features ’ll explain next code chunks. KMeans_arma KMeans_arma faster KMeans_rcpp function, however, initially outputs centroids specific number clusters. Furthermore, number columns data larger number clusters, otherwise, raises error. clustering run faster multi-core machines OpenMP enabled (eg. -fopenmp GCC). algorithm initialized 10 iterations typically sufficient convergence. initial centroids seeded using one keep_existing, static_subset, random_subset, static_spread random_spread. seed_mode equals keep_existing user supply matrix centroids.  ’ll reduce dimensions dietary_survey_IBS data using PCA particularly princomp function stats package, 2-dimensional plot resulted clusters possible,   KMeans_rcpp stated KMeans_rcpp function offers additional features comparison KMeans_arma function, Besides optimal_init, quantile_init, random kmeans++ initilizations one can specify centroids using CENTROIDS parameter running time convergence algorithm can adjusted using num_init, max_iters tol parameters num_init > 1 KMeans_rcpp returns attributes best initialization using criterion within-cluster-sum--squared-error algorithm returns following attributes: clusters, fuzzy_clusters (fuzzy = TRUE), centroids, total_SSE, best_initialization, WCSS_per_cluster, obs_per_cluster, .SS_DIV_total.SS details KMeans_rcpp can found package documentation. ’ll explain various parameters KMeans_rcpp using vector quantization example OpenImageR package,    attribute .SS_DIV_total.SS equal (total_SSE - sum(WCSS_per_cluster)) / total_SSE. pattern clustering sum squares small fraction total sum squares, whereas .SS_DIV_total.SS attribute close 1.0 observations cluster pretty well.    follow-one can take advantage Optimal_Clusters_KMeans function (indirectly uses KMeans_rcpp) estimate optimal number clusters. available criteria variance_explained, WCSSE (within-cluster-sum--squared-error), dissimilarity, silhouette, distortion_fK, AIC, BIC Adjusted_Rsquared. information criterion can found package documentation. next code chunk ’ll use distortion_fK criterion, fully described “Selection K K-means clustering, Pham., Dimov., Nguyen., (2004)” paper,  Values fixed threshold (fK_threshold = 0.85) recommended clustering, however multiple optimal clusterings highlights fact f(K) used suggest guide value number clusters final decision value adopt left discretion user.","code":"pca_dat = stats::princomp(dat)$scores[, 1:2]  km = KMeans_arma(pca_dat, clusters = 2, n_iter = 10, seed_mode = \"random_subset\",                                     verbose = T, CENTROIDS = NULL)  pr = predict_KMeans(pca_dat, km)  table(dietary_survey_IBS$class, pr)  class(km) = 'matrix'  plot_2d(data = pca_dat, clusters = as.vector(pr), centroids_medoids = as.matrix(km)) library(OpenImageR)  im = readImage('elephant.jpg')  # first resize the image to reduce the dimensions im = resizeImage(im, 75, 75, method = 'bilinear')              imageShow(im)                                                # plot the original image im2 = apply(im, 3, as.vector)                                # vectorize RGB # perform KMeans_rcpp clustering  km_rc = KMeans_rcpp(im2, clusters = 5, num_init = 5, max_iters = 100,                      initializer = 'optimal_init', verbose = F)  km_rc$between.SS_DIV_total.SS ## [1] 0.9873009 pr = predict(km_rc, newdata = im2) getcent = km_rc$centroids  getclust = km_rc$clusters  new_im = getcent[getclust, ]     # each observation is associated with the nearby centroid  dim(new_im) = c(nrow(im), ncol(im), 3)        # back-convertion to a 3-dimensional image  imageShow(new_im) opt = Optimal_Clusters_KMeans(im2, max_clusters = 10, plot_clusters = T,                                                              criterion = 'distortion_fK', fK_threshold = 0.85,                                                              initializer = 'optimal_init', tol_optimal_init = 0.2)"},{"path":"https://mlampros.github.io/ClusterR/articles/the_clusterR_package.html","id":"mini-batch-kmeans","dir":"Articles","previous_headings":"","what":"Mini-batch-kmeans","title":"Functionality of the ClusterR package","text":"Mini-batch-kmeans (http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf) variation classical k-means algorithm. particularly useful big data sets rather using whole data (k-means ) uses mini-batches random data samples optimize objective function. parameters MiniBatchKmeans algorithm almost KMeans_rcpp function ClusterR package. important differences batch_size (size mini batches) init_fraction (percentage data use initialized centroids, applies initializer equals ‘kmeans++’ ‘quantile_init’). ’ll take advantage vector quantization example show differences computation time output quality KMeans_rcpp MiniBatchKmeans functions,   First, perform k-means clustering,   mini-batch-kmeans clustering,   slight difference output quality, mini-batch-kmeans returns output average twice fast classical k-means.","code":"im_d = readImage('dog.jpg')  # first resize the image to reduce the dimensions im_d = resizeImage(im_d, 350, 350, method = 'bilinear')              imageShow(im_d)                                                # plot the original image im3 = apply(im_d, 3, as.vector)                                # vectorize RGB  dim(im3)                                              # initial dimensions of the data ## [1] 122500      3 start = Sys.time()  km_init = KMeans_rcpp(im3, clusters = 5, num_init = 5, max_iters = 100,                        initializer = 'kmeans++', verbose = F)  end = Sys.time()  t = end - start    cat('time to complete :', t, attributes(t)$units, '\\n') ## time to complete : 1.689947 secs getcent_init = km_init$centroids  getclust_init = km_init$clusters  new_im_init = getcent_init[getclust_init, ]  # each observation is associated with the nearby centroid  dim(new_im_init) = c(nrow(im_d), ncol(im_d), 3)     # back-convertion to a 3-dimensional image  imageShow(new_im_init) start = Sys.time()  km_mb = MiniBatchKmeans(im3, clusters = 5, batch_size = 20, num_init = 5, max_iters = 100,                          init_fraction = 0.2, initializer = 'kmeans++', early_stop_iter = 10,                         verbose = F)  pr_mb = predict(object = km_mb, newdata = im3) ## Warning: `predict_MBatchKMeans()` was deprecated in ClusterR 1.3.0. ## ℹ Beginning from version 1.4.0, if the fuzzy parameter is TRUE the function ##   'predict_MBatchKMeans' will return only the probabilities, whereas currently ##   it also returns the hard clusters ## ℹ The deprecated feature was likely used in the ClusterR package. ##   Please report the issue at <https://github.com/mlampros/ClusterR/issues>. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. end = Sys.time()  t = end - start    cat('time to complete :', t, attributes(t)$units, '\\n') ## time to complete : 0.9210329 secs getcent_mb = km_mb$centroids  new_im_mb = getcent_mb[pr_mb, ]   # each observation is associated with the nearby centroid  dim(new_im_mb) = c(nrow(im_d), ncol(im_d), 3)     # back-convertion to a 3-dimensional image  imageShow(new_im_mb)"},{"path":"https://mlampros.github.io/ClusterR/articles/the_clusterR_package.html","id":"k-medoids","dir":"Articles","previous_headings":"","what":"K-Medoids","title":"Functionality of the ClusterR package","text":"k-medoids algorithm (Kaufman, L., Rousseeuw, P., 1987) clustering algorithm related k-means algorithm medoid shift algorithm. k-means k-medoids algorithms partitional attempt minimize distance points labeled cluster point designated center cluster. contrast k-means algorithm, k-medoids chooses data points centers (medoids exemplars) works arbitrary metrics distances data points. useful tool determining k silhouette width. K-medoids robust noise outliers comparison k-means, minimizes sum pairwise dissimilarities instead sum squared Euclidean distances. medoid can defined object cluster whose average dissimilarity objects cluster minimal, .e. centrally located point cluster. common realization k-medoid clustering Partitioning Around Medoids (PAM) algorithm. PAM proceeds two phases: BUILD SWAP. BUILD phase, algorithm searches good set initial medoids SWAP phase possible swaps BUILD-medoids observations take place decrease objective (Clustering Object-Oriented Environment, .Struyf, M. Hubert, P. Rousseeuw., 1997). ClusterR package, Cluster_Medoids Clara_Medoids functions correspond PAM (partitioning around medoids) CLARA (clustering large applications) algorithms. following code chunk, ’ll make use mushroom data illustrate k-medoids work distance metric euclidean distance. mushroom data consist 23 categorical attributes (including class) 8124 instances. information data can found package documentation. Cluster_Medoids Cluster_Medoids function can also take - besides matrix data frame - dissimilarity matrix input. case mushroom data, features categorical (two unique values) meaningful use gower distance. gower distance applies different function predictor depending type (numeric, ordered, factor). dissimilarity measure implemented many R packages, among others cluster package (daisy function) FD package (gowdis function). ’ll take advantage gowdis function FD package also allows user-defined weights separate predictor,  Non-Weigthed-K-medoids  mentioned gowdis function FD package allows user give different weights separate variable. weights parameter can tuned, example using random search, order achieve better clustering results. instance, using following weights separate variable one can improve adjusted-rand-index (external validation) average silhouette width (internal validation),   Weigthed-K-medoids  Clara_Medoids CLARA (CLustering LARge Applications) obvious way cluster larger datasets. Instead finding medoids entire data set - also infeasible calculate dissimilarity matrix - CLARA draws small sample data applies PAM algorithm generate optimal set medoids sample. quality resulting medoids measured average dissimilarity every object entire data set medoid cluster. Clara_Medoids function ClusterR package follows logic applying Cluster_Medoids function selected sample. Clara_Medoids takes two additional parameters, samples, sample_size. first one indicates number samples draw data set, second one fraction data draw sample iteration (float number 0.0 1.0). point Clara_Medoids function take dissimilarity matrix input, Cluster_Medoids function . ’ll apply Clara_Medoids function previously used mushroom data set using hamming distance dissimilarity metric ’ll compare system time results Cluster_Medoids function. hamming distance appropriate mushroom data ’s applicable discrete variables ’s defined number attributes take different values two compared instances (Data Mining Algorithms: Explained using R, Pawel Cichosz, 2015, page 318).  hamming-Clara-Medoids   hamming-Cluster-Medoids  Using hamming distance, Clara_Medoids Cluster_Medoids functions return approximately result (comparable also gower distance results), Clara_Medoids function outputs four times faster Cluster_Medoids particular data set. using object results last two code chunks one can also plot silhouette widths using Silhouette_Dissimilarity_Plot  function. Worth mentioning dissimilarities silhouette widths Clara_Medoids function based best-selected sample entire data set, case Cluster_Medoids function.","code":"data(mushroom)  X = mushroom[, -1]  y = as.numeric(mushroom[, 1])            # convert the labels to numeric  gwd = FD::gowdis(X)           # calculate the 'gower' distance for the factor variables  gwd_mat = as.matrix(gwd)                 # convert the distances to a matrix  cm = Cluster_Medoids(gwd_mat, clusters = 2, swap_phase = TRUE, verbose = F) ## Warning: The `seed` argument of `Cluster_Medoids()` is deprecated as of ClusterR 1.2.6. ## ℹ The 'seed' parameter will be removed in version 1.4.0 ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. weights = c(4.626, 38.323, 55.899, 34.028, 169.608, 6.643, 42.08, 57.366, 37.938,                           33.081, 65.105, 18.718, 76.165, 27.596, 26.238, 0.0, 1.507, 37.314,                           32.685, 127.87, 64.019, 44.519)  gwd_w = FD::gowdis(X, w = weights)       # 'gower' distance using weights  gwd_mat_w = as.matrix(gwd_w)                 # convert the distances to a matrix  cm_w = Cluster_Medoids(gwd_mat_w, clusters = 2, swap_phase = TRUE, verbose = F) cl_X = X        # copy initial data   # the Clara_Medoids function allows only numeric attributes # so first convert to numeric  for (i in 1:ncol(cl_X)) { cl_X[, i] = as.numeric(cl_X[, i]) }  start = Sys.time()  cl_f = Clara_Medoids(cl_X, clusters = 2, distance_metric = 'hamming', samples = 5,                       sample_size = 0.2, swap_phase = TRUE, verbose = F, threads = 1)  end = Sys.time()  t = end - start    cat('time to complete :', t, attributes(t)$units, '\\n') ## time to complete : 1.743691 secs start = Sys.time()  cl_e = Cluster_Medoids(cl_X, clusters = 2, distance_metric = 'hamming', swap_phase = TRUE,                          verbose = F, threads = 1)  end = Sys.time()  t = end - start    cat('time to complete :', t, attributes(t)$units, '\\n') ## time to complete : 7.240894 secs # Silhouette Plot for the \"Clara_Medoids\" object  Silhouette_Dissimilarity_Plot(cl_f, silhouette = TRUE) ## [1] TRUE # Silhouette Plot for the \"Cluster_Medoids\" object  Silhouette_Dissimilarity_Plot(cl_e, silhouette = TRUE) ## [1] TRUE"},{"path":"https://mlampros.github.io/ClusterR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Lampros Mouselimis. Author, maintainer. Conrad Sanderson. Copyright holder.           Author C++ Armadillo library Ryan Curtin. Copyright holder.           Author C++ Armadillo library Siddharth Agrawal. Copyright holder.           Author C code Mini-Batch-Kmeans algorithm (https://github.com/siddharth-agrawal/Mini-Batch-K-Means) Brendan Frey. Copyright holder.           Author matlab code Affinity propagation algorithm (commercial use please contact author matlab code) Delbert Dueck. Copyright holder.           Author matlab code Affinity propagation algorithm Vitalie Spinu. Contributor.           Github Contributor Frederiek - Maarten Kerckhof. Contributor.           Github Contributor","code":""},{"path":"https://mlampros.github.io/ClusterR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Mouselimis L (2025). ClusterR: Gaussian Mixture Models, K-Means, Mini-Batch-Kmeans, K-Medoids Affinity Propagation Clustering. R package version 1.3.4, https://CRAN.R-project.org/package=ClusterR. Sanderson C, Curtin R (2016). “Armadillo: template-based C++ library linear algebra.” Journal Open Source Software, 1, 26. doi:10.21105/joss.00026. Sanderson C, Curtin R (2018). “User-Friendly Hybrid Sparse Matrix Class C++.” Lecture Notes Computer Science (LNCS), 10931, 422–430. doi:10.1007/978-3-319-96418-8_50. Agrawal S (2013). Mini-Batch-K-Means. https://github.com/siddharth-agrawal/Mini-Batch-K-Means. Sculley D (2010). “Web-scale k-means clustering.” ACM Digital Library. doi:10.1145/1772690.1772862. Dueck D (2009). Affinity Propagation: Clustering Data Passing Messages. Ph.D. thesis, University Toronto. https://hdl.handle.net/1807/17755. Frey B, Dueck D (2007). “Clustering Passing Messages Data Points.” Science, 315, 972–976. doi:10.1126/science.1136800. Struyf , Hubert M, Rousseeuw P (1997). “Clustering Object-Oriented Environment.” Journal Statistical Software. doi:10.18637/jss.v001.i04. Pham D, Dimov S, Nguyen C (2004). “Selection K K-means clustering.” Proceedings Institution Mechanical Engineers, Part C: Journal Mechanical Engineering Science. doi:10.1243/095440605X8298, https://www.ee.columbia.edu/~dpwe/papers/PhamDN05-kmeans.pdf.","code":"@Manual{,   title = {{ClusterR}: Gaussian Mixture Models, K-Means, Mini-Batch-Kmeans, K-Medoids and Affinity Propagation Clustering},   author = {Lampros Mouselimis},   year = {2025},   note = {R package version 1.3.4},   url = {https://CRAN.R-project.org/package=ClusterR}, } @Article{,   title = {Armadillo: a template-based C++ library for linear algebra},   author = {Conrad Sanderson and Ryan Curtin},   journal = {Journal of Open Source Software},   year = {2016},   volume = {1},   pages = {26},   doi = {10.21105/joss.00026}, } @Article{,   title = {A User-Friendly Hybrid Sparse Matrix Class in C++},   author = {Conrad Sanderson and Ryan Curtin},   journal = {Lecture Notes in Computer Science (LNCS)},   year = {2018},   volume = {10931},   pages = {422--430},   doi = {10.1007/978-3-319-96418-8_50}, } @Manual{,   title = {Mini-Batch-K-Means},   author = {Siddharth Agrawal},   year = {2013},   url = {https://github.com/siddharth-agrawal/Mini-Batch-K-Means}, } @Article{,   title = {Web-scale k-means clustering},   author = {D. Sculley},   journal = {ACM Digital Library},   year = {2010},   doi = {10.1145/1772690.1772862}, } @PhdThesis{,   title = {Affinity Propagation: Clustering Data by Passing Messages},   author = {Delbert Dueck},   year = {2009},   school = {University of Toronto},   url = {https://hdl.handle.net/1807/17755}, } @Article{,   title = {Clustering by Passing Messages Between Data Points},   author = {Brendan Frey and Delbert Dueck},   journal = {Science},   year = {2007},   volume = {315},   pages = {972--976},   doi = {10.1126/science.1136800}, } @Article{,   title = {Clustering in an Object-Oriented Environment},   author = {Anja Struyf and Mia Hubert and Peter Rousseeuw},   journal = {Journal of Statistical Software},   year = {1997},   doi = {10.18637/jss.v001.i04}, } @Article{,   title = {Selection of K in K-means clustering},   author = {D Pham and S Dimov and C Nguyen},   journal = {Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science},   year = {2004},   url = {https://www.ee.columbia.edu/~dpwe/papers/PhamDN05-kmeans.pdf},   doi = {10.1243/095440605X8298}, }"},{"path":"https://mlampros.github.io/ClusterR/index.html","id":"clusterr","dir":"","previous_headings":"","what":"ClusterR","title":"Gaussian Mixture Models, K-Means, Mini-Batch-Kmeans, K-Medoids and Affinity Propagation Clustering","text":"ClusterR package consists Gaussian mixture models, k-means, mini-batch-kmeans, k-medoids affinity propagation clustering algorithms option plot, validate, predict (new data) find optimal number clusters. package takes advantage ‘RcppArmadillo’ speed computationally intensive parts functions. details functionality ClusterR can found blog-posts (first second), Vignette package Documentation ( scroll information use docker image ) UPDATE 16-08-2018: version 1.1.4 ClusterR package allows R package maintainers perform linking packages C++ code (Rcpp) level. means Rcpp functions ClusterR package can called C++ files another package. next lines ’ll give detailed explanations can done: Assumming R package (‘PackageA’) calls one ClusterR Rcpp functions. maintainer ‘PackageA’ :  1st. install ClusterR package take advantage new functionality either CRAN using,   download latest version Github using pak package,   2nd. update DESCRIPTION file ‘PackageA’ especially LinkingTo field adding ClusterR package (besides packages),   3rd. open new C++ file (instance Rstudio) top file add following ‘headers’, ‘depends’ ‘plugins’,   available functions can found following files: inst/include/ClusterRHeader.h inst/include/affinity_propagation.h  complete minimal example :   , opening R file user can call mini_batch_kmeans function using,   Use following link report bugs/issues, https://github.com/mlampros/ClusterR/issues  UPDATE 28-11-2019: Docker images ClusterR package available download dockerhub account. images come Rstudio R-development version (latest) installed. whole process tested Ubuntu 18.04. pull & run image following,  user can also bind home directory / folder image use files specifying -v command,   latter case might first give permission privileges write access YOUR_DIR directory (necessarily) using,   USER defaults rstudio give PASSWORD preference (see https://rocker-project.org/ information).  Open web-browser depending docker image build / run give,  1st. Option personal computer,   2nd. Option cloud instance,   access Rstudio console order give username password.","code":"install.packages(\"ClusterR\") pak::pak('mlampros/ClusterR') LinkingTo: ClusterR # include <RcppArmadillo.h> # include <ClusterRHeader.h> # include <affinity_propagation.h> // [[Rcpp::depends(\"RcppArmadillo\")]] // [[Rcpp::depends(ClusterR)]] // [[Rcpp::plugins(cpp11)]] # include <RcppArmadillo.h> # include <ClusterRHeader.h> # include <affinity_propagation.h> // [[Rcpp::depends(\"RcppArmadillo\")]] // [[Rcpp::depends(ClusterR)]] // [[Rcpp::plugins(cpp11)]]   using namespace clustR;   // [[Rcpp::export]] Rcpp::List mini_batch_kmeans(arma::mat& data, int clusters, int batch_size, int max_iters, int num_init = 1,                               double init_fraction = 1.0, std::string initializer = \"kmeans++\",                                                          int early_stop_iter = 10, bool verbose = false,                                                           Rcpp::Nullable<Rcpp::NumericMatrix> CENTROIDS = R_NilValue,                                                           double tol = 1e-4, double tol_optimal_init = 0.5, int seed = 1) {    ClustHeader clust_header;    return clust_header.mini_batch_kmeans(data, clusters, batch_size, max_iters, num_init, init_fraction,                                             initializer, early_stop_iter, verbose, CENTROIDS, tol,                                                                                   tol_optimal_init, seed); } Rcpp::sourceCpp('example.cpp')              # assuming that the previous Rcpp code is included in 'example.cpp'                set.seed(1) dat = matrix(runif(100000), nrow = 1000, ncol = 100)  mbkm = mini_batch_kmeans(dat, clusters = 3, batch_size = 50, max_iters = 100, num_init = 2,                            init_fraction = 1.0, initializer = \"kmeans++\", early_stop_iter = 10,                                                     verbose = T, CENTROIDS = NULL, tol = 1e-4, tol_optimal_init = 0.5, seed = 1)                           str(mbkm) docker pull mlampros/clusterr:rstudiodev  docker run -d --name rstudio_dev -e USER=rstudio -e PASSWORD=give_here_your_password --rm -p 8787:8787 mlampros/clusterr:rstudiodev docker run -d --name rstudio_dev -e USER=rstudio -e PASSWORD=give_here_your_password --rm -p 8787:8787 -v /home/YOUR_DIR:/home/rstudio/YOUR_DIR mlampros/clusterr:rstudiodev chmod -R 777 /home/YOUR_DIR http://0.0.0.0:8787 http://Public DNS:8787"},{"path":"https://mlampros.github.io/ClusterR/index.html","id":"citation","dir":"","previous_headings":"ClusterR","what":"Citation:","title":"Gaussian Mixture Models, K-Means, Mini-Batch-Kmeans, K-Medoids and Affinity Propagation Clustering","text":"use code repository paper research please cite ClusterR original articles / software https://CRAN.R-project.org/package=ClusterR:","code":"@Manual{,   title = {{ClusterR}: Gaussian Mixture Models, K-Means, Mini-Batch-Kmeans, K-Medoids and Affinity Propagation Clustering},   author = {Lampros Mouselimis},   year = {2025},   note = {R package version 1.3.4},   url = {https://CRAN.R-project.org/package=ClusterR}, }"},{"path":"https://mlampros.github.io/ClusterR/reference/AP_affinity_propagation.html","id":null,"dir":"Reference","previous_headings":"","what":"Affinity propagation clustering — AP_affinity_propagation","title":"Affinity propagation clustering — AP_affinity_propagation","text":"Affinity propagation clustering","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/AP_affinity_propagation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Affinity propagation clustering — AP_affinity_propagation","text":"","code":"AP_affinity_propagation(   data,   p,   maxits = 1000,   convits = 100,   dampfact = 0.9,   details = FALSE,   nonoise = 0,   time = FALSE )"},{"path":"https://mlampros.github.io/ClusterR/reference/AP_affinity_propagation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Affinity propagation clustering — AP_affinity_propagation","text":"data matrix. Either similarity matrix (number rows equal number columns) 3-dimensional matrix 1st, 2nd 3rd column correspond (-index, j-index, value) triplet similarity matrix. p numeric vector size 1 size equal number rows input matrix. See details section information. maxits numeric value specifying maximum number iterations (defaults 1000) convits numeric value. estimated exemplars stay fixed convits iterations, affinity propagation algorithm terminates early (defaults 100) dampfact float number specifying update equation damping level [0.5, 1). Higher values correspond heavy damping, may needed oscillations occur (defaults 0.9) details boolean specifying details printed console nonoise float number. affinity propagation algorithm adds small amount noise data prevent degenerate cases; disables . time boolean. TRUE elapsed time printed console.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/AP_affinity_propagation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Affinity propagation clustering — AP_affinity_propagation","text":"affinity propagation algorithm automatically determines number clusters based input preference p, real-valued N-vector. p() indicates preference data point chosen exemplar. Often good choice set preferences median(data). number clusters identified can adjusted changing value accordingly. p scalar, assumes preferences shared value. number clusters eventually emerges iteratively passing messages data points update two matrices, R (Frey Dueck 2007). \"responsibility\" matrix R values r(, k) quantify well suited point k serve exemplar point relative candidate exemplars point . \"availability\" matrix contains values (, k) representing \"appropriate\" point k exemplar point , taking account points' preferences point k exemplar. matrices R initialized zeros. AP algorithm performs updates iteratively two matrices. First, \"Responsibilities\" r(, k) sent data points candidate exemplars indicate strongly data point favors candidate exemplar candidate exemplars. \"Availabilities\" (, k) sent candidate exemplars data points indicate degree candidate exemplar available cluster center data point. case, responsibilities availabilities messages provide evidence whether data point exemplar , , exemplar data point assigned. iteration message-passing procedure, sum r(k; k) + (k; k) can used identify exemplars. messages converged, two ways exist identify exemplars. first approach, data point , r(, ) + (, ) > 0, data point exemplar. second approach, data point , r(, ) + (, ) > r(, j) + (, j) equal j, data point exemplar. entire procedure terminates reaches predefined number iterations determined clusters remained constant certain number iterations... ( https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5650075/  – See chapter 2 ) Excluding main diagonal similarity matrix calculating median preference ('p') value can considered another option .","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/AP_affinity_propagation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Affinity propagation clustering — AP_affinity_propagation","text":"https://www.psi.toronto.edu/index.php?q=affinity https://www.psi.toronto.edu/affinitypropagation/faq.html https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5650075/    ( SEE chapter 2 )","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/AP_affinity_propagation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Affinity propagation clustering — AP_affinity_propagation","text":"","code":"set.seed(1) dat = matrix(sample(1:255, 2500, replace = TRUE), 100, 25)  smt = 1.0 - distance_matrix(dat, method = 'euclidean', upper = TRUE, diagonal = TRUE) diag(smt) = 0.0  ap = AP_affinity_propagation(smt, p = median(as.vector(smt)))  str(ap) #> List of 10 #>  $ K                  : int 13 #>  $ N                  : num 100 #>  $ netsim             : num -41124 #>  $ dpsim              : num -34361 #>  $ expref             : num -6763 #>  $ iterations         : int 200 #>  $ exemplars          : int [1:13] 0 8 18 26 36 42 64 66 73 75 ... #>  $ idx                : num [1, 1:100] 0 73 75 42 66 64 64 18 8 75 ... #>  $ clusters           :List of 13 #>   ..$ 18: int [1:7] 7 18 51 53 68 79 93 #>   ..$ 64: int [1:7] 5 6 37 44 46 64 78 #>   ..$ 92: int [1:6] 11 34 40 77 84 92 #>   ..$ 66: int [1:9] 4 24 31 58 61 66 72 81 83 #>   ..$ 94: int [1:13] 20 28 32 41 48 63 65 69 82 91 ... #>   ..$ 42: int [1:8] 3 16 35 42 49 60 62 99 #>   ..$ 36: int [1:10] 13 17 19 23 29 30 33 36 85 87 #>   ..$ 88: int [1:6] 10 55 70 80 88 89 #>   ..$ 75: int [1:11] 2 9 47 56 57 71 75 86 90 97 ... #>   ..$ 8 : int [1:6] 8 14 21 22 45 50 #>   ..$ 73: int [1:5] 1 25 52 59 73 #>   ..$ 26: int [1:6] 26 38 39 54 67 76 #>   ..$ 0 : int [1:6] 0 12 15 27 43 74 #>  $ clusters_vectorized: int [1:100] 0 73 75 42 66 64 64 18 8 75 ..."},{"path":"https://mlampros.github.io/ClusterR/reference/AP_preferenceRange.html","id":null,"dir":"Reference","previous_headings":"","what":"Affinity propagation preference range — AP_preferenceRange","title":"Affinity propagation preference range — AP_preferenceRange","text":"Affinity propagation preference range","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/AP_preferenceRange.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Affinity propagation preference range — AP_preferenceRange","text":"","code":"AP_preferenceRange(data, method = \"bound\", threads = 1)"},{"path":"https://mlampros.github.io/ClusterR/reference/AP_preferenceRange.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Affinity propagation preference range — AP_preferenceRange","text":"data matrix. Either similarity matrix (number rows equal number columns) 3-dimensional matrix 1st, 2nd 3rd column correspond (-index, j-index, value) triplet similarity matrix. method character string specifying preference range method use. One 'exact', 'bound'. See details section information. threads integer specifying number cores run parallel ( applies method set 'exact' computationally intensive )","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/AP_preferenceRange.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Affinity propagation preference range — AP_preferenceRange","text":"Given set similarities, data, function computes lower bound, pmin, value preference optimal number clusters (exemplars) changes 1 2, exact value preference, pmax, optimal number clusters changes n-1 n. N data points, may many N^2-N pair-wise similarities (note similarity data point k need equal similarity data point k ). may passed NxN matrix similarities, data, data(,k) similarity point point k. fact, smaller number relevant similarities need provided, case others assumed -Inf. M similarity values known, can passed Mx3 matrix data, row data contains pair data point indices corresponding similarity value: data(j,3) similarity data point data(j,1) data point data(j,2). single-cluster solution may exist, case pmin set NaN. AP_preferenceRange uses one methods compute pmin pmax: exact : Computes exact values pmin pmax (Warning: can quite slow) bound : Computes exact value pmax, estimates pmin using bound (default)","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/AP_preferenceRange.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Affinity propagation preference range — AP_preferenceRange","text":"https://www.psi.toronto.edu/affinitypropagation/preferenceRange.m","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/AP_preferenceRange.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Affinity propagation preference range — AP_preferenceRange","text":"","code":"set.seed(1) dat = matrix(sample(1:255, 2500, replace = TRUE), 100, 25)  smt = 1.0 - distance_matrix(dat, method = 'euclidean', upper = TRUE, diagonal = TRUE) diag(smt) = 0.0  ap_range = AP_preferenceRange(smt, method = \"bound\")"},{"path":"https://mlampros.github.io/ClusterR/reference/Clara_Medoids.html","id":null,"dir":"Reference","previous_headings":"","what":"Clustering large applications — Clara_Medoids","title":"Clustering large applications — Clara_Medoids","text":"Clustering large applications","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Clara_Medoids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clustering large applications — Clara_Medoids","text":"","code":"Clara_Medoids(   data,   clusters,   samples,   sample_size,   distance_metric = \"euclidean\",   minkowski_p = 1,   threads = 1,   swap_phase = TRUE,   fuzzy = FALSE,   verbose = FALSE,   seed = 1 )"},{"path":"https://mlampros.github.io/ClusterR/reference/Clara_Medoids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clustering large applications — Clara_Medoids","text":"data matrix data frame clusters number clusters samples number samples draw data set sample_size fraction data draw sample iteration. float number greater 0.0 less equal 1.0 distance_metric string specifying distance method. One ,  euclidean,  manhattan,  chebyshev,  canberra,  braycurtis,  pearson_correlation,  simple_matching_coefficient,  minkowski,  hamming,  jaccard_coefficient,  Rao_coefficient,  mahalanobis, cosine minkowski_p numeric value specifying minkowski parameter case distance_metric = \"minkowski\" threads integer specifying number cores run parallel. Openmp utilized parallelize number different sample draws swap_phase either TRUE FALSE. TRUE phases ('build' 'swap') take place. 'swap_phase' considered computationally intensive. fuzzy either TRUE FALSE. TRUE, probabilities cluster returned based distance observations medoids verbose either TRUE FALSE, indicating whether progress printed clustering seed integer value random number generator (RNG)","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Clara_Medoids.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clustering large applications — Clara_Medoids","text":"list following attributes : medoids, medoid_indices, sample_indices, best_dissimilarity, clusters, fuzzy_probs (fuzzy = TRUE), clustering_stats, dissimilarity_matrix, silhouette_matrix","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Clara_Medoids.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Clustering large applications — Clara_Medoids","text":"Clara_Medoids function implemented way 'clara' (clustering large applications) algorithm (Kaufman Rousseeuw(1990)). 'Clara_Medoids' 'Cluster_Medoids' function applied sample draw.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Clara_Medoids.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Clustering large applications — Clara_Medoids","text":"Anja Struyf, Mia Hubert, Peter J. Rousseeuw, (Feb. 1997), Clustering Object-Oriented Environment, Journal Statistical Software, Vol 1, Issue 4","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Clara_Medoids.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Clustering large applications — Clara_Medoids","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Clara_Medoids.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clustering large applications — Clara_Medoids","text":"","code":"data(dietary_survey_IBS)  dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]  dat = center_scale(dat)  clm = Clara_Medoids(dat, clusters = 3, samples = 5, sample_size = 0.2, swap_phase = TRUE)"},{"path":"https://mlampros.github.io/ClusterR/reference/Cluster_Medoids.html","id":null,"dir":"Reference","previous_headings":"","what":"Partitioning around medoids — Cluster_Medoids","title":"Partitioning around medoids — Cluster_Medoids","text":"Partitioning around medoids","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Cluster_Medoids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partitioning around medoids — Cluster_Medoids","text":"","code":"Cluster_Medoids(   data,   clusters,   distance_metric = \"euclidean\",   minkowski_p = 1,   threads = 1,   swap_phase = TRUE,   fuzzy = FALSE,   verbose = FALSE,   seed = 1 )"},{"path":"https://mlampros.github.io/ClusterR/reference/Cluster_Medoids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partitioning around medoids — Cluster_Medoids","text":"data matrix data frame. data parameter can also dissimilarity matrix, main diagonal equals 0.0 number rows equals number columns clusters number clusters distance_metric string specifying distance method. One ,  euclidean,  manhattan,  chebyshev,  canberra,  braycurtis,  pearson_correlation,  simple_matching_coefficient,  minkowski,  hamming,  jaccard_coefficient,  Rao_coefficient,  mahalanobis, cosine minkowski_p numeric value specifying minkowski parameter case distance_metric = \"minkowski\" threads integer specifying number cores run parallel swap_phase either TRUE FALSE. TRUE phases ('build' 'swap') take place. 'swap_phase' considered computationally intensive. fuzzy either TRUE FALSE. TRUE, probabilities cluster returned based distance observations medoids verbose either TRUE FALSE, indicating whether progress printed clustering seed `r lifecycle::badge(\"deprecated\")` `seed` (integer value random number generator (RNG)) longer supported removed version 1.4.0","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Cluster_Medoids.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partitioning around medoids — Cluster_Medoids","text":"list following attributes: medoids, medoid_indices, best_dissimilarity, dissimilarity_matrix, clusters, fuzzy_probs (fuzzy = TRUE), silhouette_matrix, clustering_stats","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Cluster_Medoids.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partitioning around medoids — Cluster_Medoids","text":"Due fact access book 'Finding Groups Data, Kaufman Rousseeuw, 1990' (includes exact algorithm) implemented 'Cluster_Medoids' function based paper 'Clustering Object-Oriented Environment' (see 'References'). Therefore, 'Cluster_Medoids' function approximate implementation exact one. Furthermore, comparison k-means clustering, function 'Cluster_Medoids' robust, minimizes sum unsquared dissimilarities. Moreover, need initial guesses cluster centers.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Cluster_Medoids.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partitioning around medoids — Cluster_Medoids","text":"Anja Struyf, Mia Hubert, Peter J. Rousseeuw, (Feb. 1997), Clustering Object-Oriented Environment, Journal Statistical Software, Vol 1, Issue 4","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Cluster_Medoids.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Partitioning around medoids — Cluster_Medoids","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Cluster_Medoids.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partitioning around medoids — Cluster_Medoids","text":"","code":"data(dietary_survey_IBS)  dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]  dat = center_scale(dat)  cm = Cluster_Medoids(dat, clusters = 3, distance_metric = 'euclidean', swap_phase = TRUE) #> Warning: The `seed` argument of `Cluster_Medoids()` is deprecated as of ClusterR 1.2.6. #> ℹ The 'seed' parameter will be removed in version 1.4.0"},{"path":"https://mlampros.github.io/ClusterR/reference/GMM.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian Mixture Model clustering — GMM","title":"Gaussian Mixture Model clustering — GMM","text":"Gaussian Mixture Model clustering","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/GMM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gaussian Mixture Model clustering — GMM","text":"","code":"GMM(   data,   gaussian_comps = 1,   dist_mode = \"eucl_dist\",   seed_mode = \"random_subset\",   km_iter = 10,   em_iter = 5,   verbose = FALSE,   var_floor = 1e-10,   seed = 1,   full_covariance_matrices = FALSE )"},{"path":"https://mlampros.github.io/ClusterR/reference/GMM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian Mixture Model clustering — GMM","text":"data matrix data frame gaussian_comps number gaussian mixture components dist_mode distance used seeding initial means k-means clustering. One , eucl_dist, maha_dist. seed_mode initial means seeded prior running k-means /EM algorithms. One , static_subset, random_subset, static_spread, random_spread. km_iter number iterations k-means algorithm em_iter number iterations EM algorithm verbose either TRUE FALSE; enable disable printing progress k-means EM algorithms var_floor variance floor (smallest allowed value) diagonal covariances seed integer value random number generator (RNG) full_covariance_matrices boolean. FALSE \"diagonal\" covariance matrices (.e. covariance matrix, entries outside main diagonal assumed zero) otherwise \"full\" covariance matrices returned. aware case \"full\" covariance matrices cube (3-dimensional) rather matrix output \"covariance_matrices\" value returned.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/GMM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gaussian Mixture Model clustering — GMM","text":"list consisting centroids, covariance matrix ( row matrix represents diagonal covariance matrix), weights log-likelihoods gaussian component. case Error returns error message possible causes.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/GMM.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gaussian Mixture Model clustering — GMM","text":"function R implementation 'gmm_diag' class Armadillo library. exception user defined parameter settings supported, seed_mode = 'keep_existing'. probabilistic applications, better model parameters typically learned dist_mode set maha_dist. vector quantisation applications, model parameters learned dist_mode set eucl_dist, number EM iterations set zero. general, sufficient number k-means EM iterations typically 10. number training samples much larger number Gaussians. Seeding initial means static_spread random_spread can much time consuming static_subset random_subset. k-means EM algorithms run faster multi-core machines OpenMP enabled compiler (eg. -fopenmp GCC)","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/GMM.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gaussian Mixture Model clustering — GMM","text":"http://arma.sourceforge.net/docs.html","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/GMM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gaussian Mixture Model clustering — GMM","text":"","code":"data(dietary_survey_IBS)  dat = as.matrix(dietary_survey_IBS[, -ncol(dietary_survey_IBS)])  dat = center_scale(dat)  gmm = GMM(dat, 2, \"maha_dist\", \"random_subset\", 10, 10)"},{"path":"https://mlampros.github.io/ClusterR/reference/KMeans_arma.html","id":null,"dir":"Reference","previous_headings":"","what":"k-means using the Armadillo library — KMeans_arma","title":"k-means using the Armadillo library — KMeans_arma","text":"k-means using Armadillo library","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/KMeans_arma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"k-means using the Armadillo library — KMeans_arma","text":"","code":"KMeans_arma(   data,   clusters,   n_iter = 10,   seed_mode = \"random_subset\",   verbose = FALSE,   CENTROIDS = NULL,   seed = 1 )"},{"path":"https://mlampros.github.io/ClusterR/reference/KMeans_arma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"k-means using the Armadillo library — KMeans_arma","text":"data matrix data frame clusters number clusters n_iter number clustering iterations (10 typically sufficient) seed_mode initial centroids seeded. One , keep_existing, static_subset, random_subset, static_spread, random_spread. verbose either TRUE FALSE, indicating whether progress printed clustering CENTROIDS matrix initial cluster centroids. rows CENTROIDS matrix equal number clusters columns equal columns data. CENTROIDS used combination seed_mode 'keep_existing'. seed integer value random number generator (RNG)","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/KMeans_arma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"k-means using the Armadillo library — KMeans_arma","text":"centroids matrix. case Error returns error message, whereas case empty centroids-matrix returns warning-message.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/KMeans_arma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"k-means using the Armadillo library — KMeans_arma","text":"function R implementation 'kmeans' class Armadillo library. faster KMeans_rcpp function lacks features. info see details section KMeans_rcpp function. number columns larger number clusters CENTROIDS. clustering fails, means matrix reset bool set false returned. clustering run faster multi-core machines OpenMP enabled compiler (eg. -fopenmp GCC)","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/KMeans_arma.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"k-means using the Armadillo library — KMeans_arma","text":"http://arma.sourceforge.net/docs.html","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/KMeans_arma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"k-means using the Armadillo library — KMeans_arma","text":"","code":"data(dietary_survey_IBS)  dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]  dat = center_scale(dat)  km = KMeans_arma(dat, clusters = 2, n_iter = 10, \"random_subset\")"},{"path":"https://mlampros.github.io/ClusterR/reference/KMeans_rcpp.html","id":null,"dir":"Reference","previous_headings":"","what":"k-means using RcppArmadillo — KMeans_rcpp","title":"k-means using RcppArmadillo — KMeans_rcpp","text":"k-means using RcppArmadillo","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/KMeans_rcpp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"k-means using RcppArmadillo — KMeans_rcpp","text":"","code":"KMeans_rcpp(   data,   clusters,   num_init = 1,   max_iters = 100,   initializer = \"kmeans++\",   fuzzy = FALSE,   verbose = FALSE,   CENTROIDS = NULL,   tol = 1e-04,   tol_optimal_init = 0.3,   seed = 1 )"},{"path":"https://mlampros.github.io/ClusterR/reference/KMeans_rcpp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"k-means using RcppArmadillo — KMeans_rcpp","text":"data matrix data frame clusters number clusters num_init number times algorithm run different centroid seeds max_iters maximum number clustering iterations initializer method initialization. One , optimal_init, quantile_init, kmeans++ random. See details information fuzzy either TRUE FALSE. TRUE, prediction probabilities calculated using distance observations centroids verbose either TRUE FALSE, indicating whether progress printed clustering. CENTROIDS matrix initial cluster centroids. rows CENTROIDS matrix equal number clusters columns equal columns data. tol float number. , case iteration (iteration > 1 iteration < max_iters) 'tol' greater squared norm centroids, kmeans converged tol_optimal_init tolerance value 'optimal_init' initializer. higher value , far appart centroids . seed integer value random number generator (RNG)","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/KMeans_rcpp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"k-means using RcppArmadillo — KMeans_rcpp","text":"list following attributes: clusters, fuzzy_clusters (fuzzy = TRUE), centroids, total_SSE, best_initialization, WCSS_per_cluster, obs_per_cluster, .SS_DIV_total.SS","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/KMeans_rcpp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"k-means using RcppArmadillo — KMeans_rcpp","text":"function following features comparison KMeans_arma function: Besides optimal_init, quantile_init, random kmeans++ initilizations one can specify centroids using CENTROIDS parameter. running time convergence algorithm can adjusted using num_init, max_iters tol parameters. num_init > 1 KMeans_rcpp returns attributes best initialization using criterion within-cluster-sum--squared-error. —————initializers———————- optimal_init   : initializer adds rows data incrementally, checking already exist centroid-matrix [ experimental ] quantile_init  : initialization centroids using cummulative distance observations removing potential duplicates [ experimental ] kmeans++       : kmeans++ initialization. Reference : http://theory.stanford.edu/~sergei/papers/kMeansPP-soda.pdf http://stackoverflow.com/questions/5466323/-exactly--k-means-work random         : random selection data rows initial centroids","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/KMeans_rcpp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"k-means using RcppArmadillo — KMeans_rcpp","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/KMeans_rcpp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"k-means using RcppArmadillo — KMeans_rcpp","text":"","code":"data(dietary_survey_IBS)  dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]  dat = center_scale(dat)  km = KMeans_rcpp(dat, clusters = 2, num_init = 5, max_iters = 100, initializer = 'kmeans++')"},{"path":"https://mlampros.github.io/ClusterR/reference/MiniBatchKmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Mini-batch-k-means using RcppArmadillo — MiniBatchKmeans","title":"Mini-batch-k-means using RcppArmadillo — MiniBatchKmeans","text":"Mini-batch-k-means using RcppArmadillo","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/MiniBatchKmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mini-batch-k-means using RcppArmadillo — MiniBatchKmeans","text":"","code":"MiniBatchKmeans(   data,   clusters,   batch_size = 10,   num_init = 1,   max_iters = 100,   init_fraction = 1,   initializer = \"kmeans++\",   early_stop_iter = 10,   verbose = FALSE,   CENTROIDS = NULL,   tol = 1e-04,   tol_optimal_init = 0.3,   seed = 1 )"},{"path":"https://mlampros.github.io/ClusterR/reference/MiniBatchKmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mini-batch-k-means using RcppArmadillo — MiniBatchKmeans","text":"data matrix data frame clusters number clusters batch_size size mini batches num_init number times algorithm run different centroid seeds max_iters maximum number clustering iterations init_fraction percentage data use initialization centroids (applies initializer kmeans++ optimal_init). float number 0.0 1.0. initializer method initialization. One , optimal_init, quantile_init, kmeans++ random. See details information early_stop_iter continue many iterations calculation best within-cluster-sum--squared-error verbose either TRUE FALSE, indicating whether progress printed clustering CENTROIDS matrix initial cluster centroids. rows CENTROIDS matrix equal number clusters columns equal columns data tol float number. , case iteration (iteration > 1 iteration < max_iters) 'tol' greater squared norm centroids, kmeans converged tol_optimal_init tolerance value 'optimal_init' initializer. higher value , far appart centroids . seed integer value random number generator (RNG)","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/MiniBatchKmeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mini-batch-k-means using RcppArmadillo — MiniBatchKmeans","text":"list following attributes: centroids, WCSS_per_cluster, best_initialization, iters_per_initialization","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/MiniBatchKmeans.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mini-batch-k-means using RcppArmadillo — MiniBatchKmeans","text":"function performs k-means clustering using mini batches. —————initializers———————- optimal_init   : initializer adds rows data incrementally, checking already exist centroid-matrix   [ experimental ] quantile_init  : initialization centroids using cummulative distance observations removing potential duplicates  [ experimental ] kmeans++       : kmeans++ initialization. Reference : http://theory.stanford.edu/~sergei/papers/kMeansPP-soda.pdf http://stackoverflow.com/questions/5466323/-exactly--k-means-work random         : random selection data rows initial centroids","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/MiniBatchKmeans.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mini-batch-k-means using RcppArmadillo — MiniBatchKmeans","text":"http://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf, https://github.com/siddharth-agrawal/Mini-Batch-K-Means","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/MiniBatchKmeans.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Mini-batch-k-means using RcppArmadillo — MiniBatchKmeans","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/MiniBatchKmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mini-batch-k-means using RcppArmadillo — MiniBatchKmeans","text":"","code":"data(dietary_survey_IBS)  dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]  dat = center_scale(dat)  MbatchKm = MiniBatchKmeans(dat, clusters = 2, batch_size = 20, num_init = 5, early_stop_iter = 10)"},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_GMM.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal number of Clusters for the gaussian mixture models — Optimal_Clusters_GMM","title":"Optimal number of Clusters for the gaussian mixture models — Optimal_Clusters_GMM","text":"Optimal number Clusters gaussian mixture models","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_GMM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal number of Clusters for the gaussian mixture models — Optimal_Clusters_GMM","text":"","code":"Optimal_Clusters_GMM(   data,   max_clusters,   criterion = \"AIC\",   dist_mode = \"eucl_dist\",   seed_mode = \"random_subset\",   km_iter = 10,   em_iter = 5,   verbose = FALSE,   var_floor = 1e-10,   plot_data = TRUE,   seed = 1 )"},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_GMM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal number of Clusters for the gaussian mixture models — Optimal_Clusters_GMM","text":"data matrix data frame max_clusters either numeric value, contiguous non-continguous numeric vector specifying cluster search space criterion one 'AIC' 'BIC' dist_mode distance used seeding initial means k-means clustering. One , eucl_dist, maha_dist. seed_mode initial means seeded prior running k-means /EM algorithms. One , static_subset, random_subset, static_spread, random_spread. km_iter number iterations k-means algorithm em_iter number iterations EM algorithm verbose either TRUE FALSE; enable disable printing progress k-means EM algorithms var_floor variance floor (smallest allowed value) diagonal covariances plot_data either TRUE FALSE indicating whether results function plotted seed integer value random number generator (RNG)","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_GMM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal number of Clusters for the gaussian mixture models — Optimal_Clusters_GMM","text":"vector either AIC BIC iteration. case Error returns error message possible causes.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_GMM.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal number of Clusters for the gaussian mixture models — Optimal_Clusters_GMM","text":"AIC  : Akaike information criterion BIC  : Bayesian information criterion case max_clusters parameter contiguous non-contiguous vector plotting disabled. Therefore, plotting enabled max_clusters parameter length 1.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_GMM.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal number of Clusters for the gaussian mixture models — Optimal_Clusters_GMM","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_GMM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal number of Clusters for the gaussian mixture models — Optimal_Clusters_GMM","text":"","code":"data(dietary_survey_IBS)  dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]  dat = center_scale(dat)  opt_gmm = Optimal_Clusters_GMM(dat, 10, criterion = \"AIC\", plot_data = FALSE)   #---------------------------- # non-contiguous search space #----------------------------  search_space = c(2,5)  opt_gmm = Optimal_Clusters_GMM(dat, search_space, criterion = \"AIC\", plot_data = FALSE)"},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_KMeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal number of Clusters for Kmeans or Mini-Batch-Kmeans — Optimal_Clusters_KMeans","title":"Optimal number of Clusters for Kmeans or Mini-Batch-Kmeans — Optimal_Clusters_KMeans","text":"Optimal number Clusters Kmeans Mini-Batch-Kmeans","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_KMeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal number of Clusters for Kmeans or Mini-Batch-Kmeans — Optimal_Clusters_KMeans","text":"","code":"Optimal_Clusters_KMeans(   data,   max_clusters,   criterion = \"variance_explained\",   fK_threshold = 0.85,   num_init = 1,   max_iters = 200,   initializer = \"kmeans++\",   tol = 1e-04,   plot_clusters = TRUE,   verbose = FALSE,   tol_optimal_init = 0.3,   seed = 1,   mini_batch_params = NULL )"},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_KMeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal number of Clusters for Kmeans or Mini-Batch-Kmeans — Optimal_Clusters_KMeans","text":"data matrix data frame max_clusters either numeric value, contiguous non-continguous numeric vector specifying cluster search space criterion one variance_explained, WCSSE, dissimilarity, silhouette, distortion_fK, AIC, BIC Adjusted_Rsquared. See details information. fK_threshold float number used 'distortion_fK' criterion num_init number times algorithm run different centroid seeds max_iters maximum number clustering iterations initializer method initialization. One , optimal_init, quantile_init, kmeans++ random. See details information tol float number. , case iteration (iteration > 1 iteration < max_iters) 'tol' greater squared norm centroids, kmeans converged plot_clusters either TRUE FALSE, indicating whether results Optimal_Clusters_KMeans function plotted verbose either TRUE FALSE, indicating whether progress printed clustering tol_optimal_init tolerance value 'optimal_init' initializer. higher value , far appart centroids . seed integer value random number generator (RNG) mini_batch_params either NULL list following parameters : batch_size, init_fraction, early_stop_iter. NULL optimal number clusters found based Mini-Batch-Kmeans. See details examples sections information.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_KMeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal number of Clusters for Kmeans or Mini-Batch-Kmeans — Optimal_Clusters_KMeans","text":"vector results specified criterion. plot_clusters TRUE plots also results.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_KMeans.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal number of Clusters for Kmeans or Mini-Batch-Kmeans — Optimal_Clusters_KMeans","text":"—————criteria————————– variance_explained : sum within-cluster-sum--squares---clusters divided total sum squares WCSSE              : sum within-cluster-sum--squares---clusters dissimilarity      : average intra-cluster-dissimilarity clusters (distance metric defaults euclidean) silhouette         : average silhouette width first average per cluster silhouette computed global average (distance metric defaults euclidean). compute silhouette width cluster separately see 'silhouette_of_clusters()' function distortion_fK      : criterion based following paper, 'Selection K K-means clustering' (https://www.ee.columbia.edu/~dpwe/papers/PhamDN05-kmeans.pdf) AIC                : Akaike information criterion BIC                : Bayesian information criterion Adjusted_Rsquared  : adjusted R^2 statistic —————initializers———————- optimal_init   : initializer adds rows data incrementally, checking already exist centroid-matrix  [ experimental ] quantile_init  : initialization centroids using cummulative distance observations removing potential duplicates   [ experimental ] kmeans++       : kmeans++ initialization. Reference : http://theory.stanford.edu/~sergei/papers/kMeansPP-soda.pdf http://stackoverflow.com/questions/5466323/-exactly--k-means-work random         : random selection data rows initial centroids mini_batch_params parameter NULL optimal number clusters found based Mini-batch-Kmeans algorithm, otherwise based Kmeans. higher init_fraction parameter close results Mini-Batch-Kmeans Kmeans . case max_clusters parameter contiguous non-contiguous vector plotting disabled. Therefore, plotting enabled max_clusters parameter length 1. Moreover, distortion_fK criterion computed max_clusters parameter contiguous non-continguous vector ( distortion_fK criterion requires consecutive clusters ). applies also Adjusted_Rsquared criterion returns incorrect output.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_KMeans.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal number of Clusters for Kmeans or Mini-Batch-Kmeans — Optimal_Clusters_KMeans","text":"https://www.ee.columbia.edu/~dpwe/papers/PhamDN05-kmeans.pdf","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_KMeans.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal number of Clusters for Kmeans or Mini-Batch-Kmeans — Optimal_Clusters_KMeans","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_KMeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal number of Clusters for Kmeans or Mini-Batch-Kmeans — Optimal_Clusters_KMeans","text":"","code":"data(dietary_survey_IBS)  dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]  dat = center_scale(dat)   #------- # kmeans #-------  opt_km = Optimal_Clusters_KMeans(dat, max_clusters = 10, criterion = \"distortion_fK\",                                   plot_clusters = FALSE)  #------------------ # mini-batch-kmeans #------------------   params_mbkm = list(batch_size = 10, init_fraction = 0.3, early_stop_iter = 10)  opt_mbkm = Optimal_Clusters_KMeans(dat, max_clusters = 10, criterion = \"distortion_fK\",                                     plot_clusters = FALSE, mini_batch_params = params_mbkm)   #---------------------------- # non-contiguous search space #----------------------------  search_space = c(2,5)  opt_km = Optimal_Clusters_KMeans(dat, max_clusters = search_space,                                   criterion = \"variance_explained\",                                   plot_clusters = FALSE)"},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_Medoids.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal number of Clusters for the partitioning around Medoids functions — Optimal_Clusters_Medoids","title":"Optimal number of Clusters for the partitioning around Medoids functions — Optimal_Clusters_Medoids","text":"Optimal number Clusters partitioning around Medoids functions","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_Medoids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal number of Clusters for the partitioning around Medoids functions — Optimal_Clusters_Medoids","text":"","code":"Optimal_Clusters_Medoids(   data,   max_clusters,   distance_metric,   criterion = \"dissimilarity\",   clara_samples = 0,   clara_sample_size = 0,   minkowski_p = 1,   swap_phase = TRUE,   threads = 1,   verbose = FALSE,   plot_clusters = TRUE,   seed = 1 )"},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_Medoids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal number of Clusters for the partitioning around Medoids functions — Optimal_Clusters_Medoids","text":"data matrix data.frame. clara_samples clara_sample_size equal 0, data parameter can also dissimilarity matrix, main diagonal equals 0.0 number rows equals number columns max_clusters either numeric value, contiguous non-continguous numeric vector specifying cluster search space distance_metric string specifying distance method. One ,  euclidean,  manhattan,  chebyshev,  canberra,  braycurtis,  pearson_correlation,  simple_matching_coefficient,  minkowski,  hamming,  jaccard_coefficient,  Rao_coefficient,  mahalanobis, cosine criterion one 'dissimilarity' 'silhouette' clara_samples number samples draw data set case clustering large applications (clara) clara_sample_size fraction data draw sample iteration case clustering large applications (clara). float number greater 0.0 less equal 1.0 minkowski_p numeric value specifying minkowski parameter case distance_metric = \"minkowski\" swap_phase either TRUE FALSE. TRUE phases ('build' 'swap') take place. 'swap_phase' considered computationally intensive. threads integer specifying number cores run parallel. Openmp utilized parallelize number sample draws verbose either TRUE FALSE, indicating whether progress printed clustering plot_clusters TRUE FALSE, indicating whether iterative results plotted. See details section information seed integer value random number generator (RNG)","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_Medoids.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal number of Clusters for the partitioning around Medoids functions — Optimal_Clusters_Medoids","text":"list length equal max_clusters parameter (first sublist equals NULL, dissimilarities silhouette widths can calculated number clusters > 1). plot_clusters TRUE function plots also results.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_Medoids.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Optimal number of Clusters for the partitioning around Medoids functions — Optimal_Clusters_Medoids","text":"case plot_clusters = TRUE, first plot either plot dissimilarities dissimilarities silhouette widths giving indication optimal number clusters. , user asked give optimal value number clusters second plot appear either dissimilarities silhouette widths belonging cluster. case max_clusters parameter contiguous non-contiguous vector plotting disabled. Therefore, plotting enabled max_clusters parameter length 1.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_Medoids.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Optimal number of Clusters for the partitioning around Medoids functions — Optimal_Clusters_Medoids","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Optimal_Clusters_Medoids.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Optimal number of Clusters for the partitioning around Medoids functions — Optimal_Clusters_Medoids","text":"","code":"if (FALSE) { # \\dontrun{ data(soybean)  dat = soybean[, -ncol(soybean)]  opt_md = Optimal_Clusters_Medoids(dat, 10, 'jaccard_coefficient', plot_clusters = FALSE)   #---------------------------- # non-contiguous search space #----------------------------  search_space = c(2,5)  opt_md = Optimal_Clusters_Medoids(dat, search_space, 'jaccard_coefficient', plot_clusters = FALSE)  } # }"},{"path":"https://mlampros.github.io/ClusterR/reference/Silhouette_Dissimilarity_Plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot of silhouette widths or dissimilarities — Silhouette_Dissimilarity_Plot","title":"Plot of silhouette widths or dissimilarities — Silhouette_Dissimilarity_Plot","text":"Plot silhouette widths dissimilarities","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Silhouette_Dissimilarity_Plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot of silhouette widths or dissimilarities — Silhouette_Dissimilarity_Plot","text":"","code":"Silhouette_Dissimilarity_Plot(evaluation_object, silhouette = TRUE)"},{"path":"https://mlampros.github.io/ClusterR/reference/Silhouette_Dissimilarity_Plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot of silhouette widths or dissimilarities — Silhouette_Dissimilarity_Plot","text":"evaluation_object output either Cluster_Medoids Clara_Medoids function silhouette either TRUE FALSE, indicating whether silhouette widths dissimilarities plotted","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Silhouette_Dissimilarity_Plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot of silhouette widths or dissimilarities — Silhouette_Dissimilarity_Plot","text":"TRUE either silhouette widths dissimilarities plotted successfully, otherwise FALSE","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Silhouette_Dissimilarity_Plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot of silhouette widths or dissimilarities — Silhouette_Dissimilarity_Plot","text":"function takes result-object Cluster_Medoids Clara_Medoids function depending argument silhouette plots either dissimilarities silhouette widths observations belonging cluster.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Silhouette_Dissimilarity_Plot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot of silhouette widths or dissimilarities — Silhouette_Dissimilarity_Plot","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/Silhouette_Dissimilarity_Plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot of silhouette widths or dissimilarities — Silhouette_Dissimilarity_Plot","text":"","code":"# data(soybean)  # dat = soybean[, -ncol(soybean)]  # cm = Cluster_Medoids(dat, clusters = 5, distance_metric = 'jaccard_coefficient')  # plt_sd = Silhouette_Dissimilarity_Plot(cm, silhouette = TRUE)"},{"path":"https://mlampros.github.io/ClusterR/reference/center_scale.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to scale and/or center the data — center_scale","title":"Function to scale and/or center the data — center_scale","text":"Function scale /center data","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/center_scale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to scale and/or center the data — center_scale","text":"","code":"center_scale(data, mean_center = TRUE, sd_scale = TRUE)"},{"path":"https://mlampros.github.io/ClusterR/reference/center_scale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to scale and/or center the data — center_scale","text":"data matrix data frame mean_center either TRUE FALSE. mean_center TRUE mean column subtracted sd_scale either TRUE FALSE. See details section information","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/center_scale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to scale and/or center the data — center_scale","text":"matrix","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/center_scale.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Function to scale and/or center the data — center_scale","text":"sd_scale TRUE mean_center TRUE column divided standard deviation. sd_scale TRUE mean_center FALSE column divided sqrt( sum(x^2) / (n-1) ). case missing values function raises error. case standard deviation equals zero standard deviation replaced 1.0, NaN's can avoided division","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/center_scale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to scale and/or center the data — center_scale","text":"","code":"data(dietary_survey_IBS)  dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]  dat = center_scale(dat, mean_center = TRUE, sd_scale = TRUE)"},{"path":"https://mlampros.github.io/ClusterR/reference/cost_clusters_from_dissim_medoids.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the cost and clusters based on an input dissimilarity matrix and medoids — cost_clusters_from_dissim_medoids","title":"Compute the cost and clusters based on an input dissimilarity matrix and medoids — cost_clusters_from_dissim_medoids","text":"Compute cost clusters based input dissimilarity matrix medoids","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/cost_clusters_from_dissim_medoids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the cost and clusters based on an input dissimilarity matrix and medoids — cost_clusters_from_dissim_medoids","text":"","code":"cost_clusters_from_dissim_medoids(data, medoids)"},{"path":"https://mlampros.github.io/ClusterR/reference/cost_clusters_from_dissim_medoids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the cost and clusters based on an input dissimilarity matrix and medoids — cost_clusters_from_dissim_medoids","text":"data dissimilarity matrix, main diagonal equals 0.0 number rows equals number columns medoids vector output medoids 'Cluster_Medoids', 'Clara_Medoids' 'partition around medoids' function","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/cost_clusters_from_dissim_medoids.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the cost and clusters based on an input dissimilarity matrix and medoids — cost_clusters_from_dissim_medoids","text":"list object includes cost clusters","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/cost_clusters_from_dissim_medoids.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute the cost and clusters based on an input dissimilarity matrix and medoids — cost_clusters_from_dissim_medoids","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/cost_clusters_from_dissim_medoids.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the cost and clusters based on an input dissimilarity matrix and medoids — cost_clusters_from_dissim_medoids","text":"","code":"data(dietary_survey_IBS) dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)] dat = center_scale(dat)  cm = Cluster_Medoids(dat, clusters = 3, distance_metric = 'euclidean', swap_phase = TRUE) res = cost_clusters_from_dissim_medoids(data = cm$dissimilarity_matrix, medoids = cm$medoid_indices)  # cm$best_dissimilarity == res$cost # table(cm$clusters, res$clusters)"},{"path":"https://mlampros.github.io/ClusterR/reference/dietary_survey_IBS.html","id":null,"dir":"Reference","previous_headings":"","what":"Synthetic data using a dietary survey of patients with irritable bowel syndrome (IBS) — dietary_survey_IBS","title":"Synthetic data using a dietary survey of patients with irritable bowel syndrome (IBS) — dietary_survey_IBS","text":"data based article \"dietary survey\tpatients\tirritable bowel syndrome\". mean standard deviation table 1 (Foods perceived causing worsening irritable bowel syndrome symptoms IBS group digestive symptoms healthy comparative group) used generate synthetic data.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/dietary_survey_IBS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Synthetic data using a dietary survey of patients with irritable bowel syndrome (IBS) — dietary_survey_IBS","text":"","code":"data(dietary_survey_IBS)"},{"path":"https://mlampros.github.io/ClusterR/reference/dietary_survey_IBS.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Synthetic data using a dietary survey of patients with irritable bowel syndrome (IBS) — dietary_survey_IBS","text":"data frame 400 Instances 43 attributes (including class attribute, \"class\")","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/dietary_survey_IBS.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Synthetic data using a dietary survey of patients with irritable bowel syndrome (IBS) — dietary_survey_IBS","text":"predictors : bread, wheat, pasta, breakfast_cereal, yeast, spicy_food, curry, chinese_takeaway, chilli, cabbage, onion, garlic, potatoes, pepper, vegetables_unspecified, tomato, beans_and_pulses, mushroom, fatty_foods_unspecified, sauces, chocolate, fries, crisps, desserts, eggs, red_meat, processed_meat, pork, chicken, fish_shellfish, dairy_products_unspecified, cheese, cream, milk, fruit_unspecified, nuts_and_seeds, orange, apple, banana, grapes, alcohol, caffeine response variable (\"class\") consists two groups: healthy-group (class == 0) vs. IBS-patients (class == 1)","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/dietary_survey_IBS.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Synthetic data using a dietary survey of patients with irritable bowel syndrome (IBS) — dietary_survey_IBS","text":"P. Hayes, C. Corish, E. O'Mahony, E. M. M. Quigley (May 2013). dietary survey patients irritable bowel syndrome. Journal Human Nutrition Dietetics.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/dietary_survey_IBS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Synthetic data using a dietary survey of patients with irritable bowel syndrome (IBS) — dietary_survey_IBS","text":"","code":"data(dietary_survey_IBS)  X = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]  y = dietary_survey_IBS[, ncol(dietary_survey_IBS)]"},{"path":"https://mlampros.github.io/ClusterR/reference/distance_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Distance matrix calculation — distance_matrix","title":"Distance matrix calculation — distance_matrix","text":"Distance matrix calculation","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/distance_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distance matrix calculation — distance_matrix","text":"","code":"distance_matrix(   data,   method = \"euclidean\",   upper = FALSE,   diagonal = FALSE,   minkowski_p = 1,   threads = 1 )"},{"path":"https://mlampros.github.io/ClusterR/reference/distance_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distance matrix calculation — distance_matrix","text":"data matrix data frame method string specifying distance method. One ,  euclidean,  manhattan,  chebyshev,  canberra,  braycurtis,  pearson_correlation,  simple_matching_coefficient,  minkowski,  hamming,  jaccard_coefficient,  Rao_coefficient,  mahalanobis, cosine upper either TRUE FALSE specifying upper triangle distance matrix returned. FALSE upper triangle filled NA's diagonal either TRUE FALSE specifying diagonal distance matrix returned. FALSE diagonal filled NA's minkowski_p numeric value specifying minkowski parameter case method = \"minkowski\" threads number cores run parallel (OpenMP available)","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/distance_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Distance matrix calculation — distance_matrix","text":"matrix","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/distance_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Distance matrix calculation — distance_matrix","text":"","code":"data(dietary_survey_IBS)  dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]  dat = distance_matrix(dat, method = 'euclidean', upper = TRUE, diagonal = TRUE)"},{"path":"https://mlampros.github.io/ClusterR/reference/entropy_formula.html","id":null,"dir":"Reference","previous_headings":"","what":"entropy formula (used in external_validation function) — entropy_formula","title":"entropy formula (used in external_validation function) — entropy_formula","text":"entropy formula (used external_validation function)","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/entropy_formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"entropy formula (used in external_validation function) — entropy_formula","text":"","code":"entropy_formula(x_vec)"},{"path":"https://mlampros.github.io/ClusterR/reference/external_validation.html","id":null,"dir":"Reference","previous_headings":"","what":"external clustering validation — external_validation","title":"external clustering validation — external_validation","text":"external clustering validation","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/external_validation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"external clustering validation — external_validation","text":"","code":"external_validation(   true_labels,   clusters,   method = \"adjusted_rand_index\",   summary_stats = FALSE )"},{"path":"https://mlampros.github.io/ClusterR/reference/external_validation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"external clustering validation — external_validation","text":"true_labels numeric vector length equal length clusters vector clusters numeric vector ( result clustering method ) length equal length true_labels method one rand_index,  adjusted_rand_index,  jaccard_index,  fowlkes_Mallows_index,  mirkin_metric,  purity,  entropy,  nmi (normalized mutual information), var_info (variation information), nvi (normalized variation information) summary_stats besides available methods summary_stats parameter prints also specificity, sensitivity, precision, recall F-measure clusters","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/external_validation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"external clustering validation — external_validation","text":"summary_stats FALSE function returns float number, otherwise returns also summary statistics table","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/external_validation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"external clustering validation — external_validation","text":"function uses external validation methods evaluate clustering results","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/external_validation.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"external clustering validation — external_validation","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/external_validation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"external clustering validation — external_validation","text":"","code":"data(dietary_survey_IBS)  dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]  X = center_scale(dat)  km = KMeans_rcpp(X, clusters = 2, num_init = 5, max_iters = 100, initializer = 'kmeans++')  res = external_validation(dietary_survey_IBS$class, km$clusters, method = \"adjusted_rand_index\")"},{"path":"https://mlampros.github.io/ClusterR/reference/function_interactive.html","id":null,"dir":"Reference","previous_headings":"","what":"Interactive function for consecutive plots ( using dissimilarities or the silhouette widths of the observations ) — function_interactive","title":"Interactive function for consecutive plots ( using dissimilarities or the silhouette widths of the observations ) — function_interactive","text":"Interactive function consecutive plots ( using dissimilarities silhouette widths observations )","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/function_interactive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interactive function for consecutive plots ( using dissimilarities or the silhouette widths of the observations ) — function_interactive","text":"","code":"function_interactive(evaluation_objects, max_clusters, silhouette = FALSE)"},{"path":"https://mlampros.github.io/ClusterR/reference/mushroom.html","id":null,"dir":"Reference","previous_headings":"","what":"The mushroom data — mushroom","title":"The mushroom data — mushroom","text":"data set includes descriptions hypothetical samples corresponding 23 species gilled mushrooms Agaricus Lepiota Family (pp. 500-525). species identified definitely edible, definitely poisonous, unknown edibility recommended. latter class combined poisonous one. Guide clearly states simple rule determining edibility mushroom; rule like 'leaflets three, let ' Poisonous Oak Ivy.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/mushroom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The mushroom data — mushroom","text":"","code":"data(mushroom)"},{"path":"https://mlampros.github.io/ClusterR/reference/mushroom.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The mushroom data — mushroom","text":"data frame 8124 Instances 23 attributes (including class attribute, \"class\")","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/mushroom.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The mushroom data — mushroom","text":"column names data (including class) appear following order: 1. class: edible=e, poisonous=p 2. cap-shape: bell=b, conical=c, convex=x, flat=f, knobbed=k, sunken=s 3. cap-surface: fibrous=f, grooves=g, scaly=y, smooth=s 4. cap-color: brown=n, buff=b, cinnamon=c, gray=g, green=r, pink=p, purple=u, red=e, white=w, yellow=y 5. bruises: bruises=t, =f 6. odor: almond=, anise=l, creosote=c, fishy=y, foul=f, musty=m, none=n, pungent=p, spicy=s 7. gill-attachment: attached=, descending=d, free=f, notched=n 8. gill-spacing: close=c, crowded=w, distant=d 9. gill-size: broad=b, narrow=n 10. gill-color: black=k, brown=n, buff=b, chocolate=h, gray=g, green=r, orange=o, pink=p, purple=u, red=e, white=w, yellow=y 11. stalk-shape: enlarging=e, tapering=t 12. stalk-root: bulbous=b, club=c, cup=u, equal=e, rhizomorphs=z, rooted=r, missing=? 13. stalk-surface--ring: fibrous=f, scaly=y, silky=k, smooth=s 14. stalk-surface--ring: fibrous=f, scaly=y, silky=k, smooth=s 15. stalk-color--ring: brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y 16. stalk-color--ring: brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y 17. veil-type: partial=p, universal=u 18. veil-color: brown=n, orange=o, white=w, yellow=y 19. ring-number: none=n, one=o, two=t 20. ring-type: cobwebby=c, evanescent=e, flaring=f, large=l, none=n, pendant=p, sheathing=s, zone=z 21. spore-print-color: black=k, brown=n, buff=b, chocolate=h, green=r, orange=o, purple=u, white=w, yellow=y 22. population: abundant=, clustered=c, numerous=n, scattered=s, several=v, solitary=y 23. habitat: grasses=g, leaves=l, meadows=m, paths=p, urban=u, waste=w, woods=d","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/mushroom.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The mushroom data — mushroom","text":"Mushroom records drawn Audubon Society Field Guide North American Mushrooms (1981). G. H. Lincoff (Pres.), New York: Alfred . Knopf Donor:  Jeff Schlimmer (Jeffrey.Schlimmer@.gp.cs.cmu.edu) download source: https://archive.ics.uci.edu/ml/datasets/Mushroom","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/mushroom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The mushroom data — mushroom","text":"","code":"data(mushroom)  X = mushroom[, -1]  y = mushroom[, 1]"},{"path":"https://mlampros.github.io/ClusterR/reference/plot_2d.html","id":null,"dir":"Reference","previous_headings":"","what":"2-dimensional plots — plot_2d","title":"2-dimensional plots — plot_2d","text":"2-dimensional plots","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/plot_2d.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"2-dimensional plots — plot_2d","text":"","code":"plot_2d(data, clusters, centroids_medoids)"},{"path":"https://mlampros.github.io/ClusterR/reference/plot_2d.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"2-dimensional plots — plot_2d","text":"data 2-dimensional matrix data frame clusters numeric vector length equal number rows data, result clustering method centroids_medoids matrix centroids medoids. rows centroids_medoids equal length unique values clusters columns equal columns data.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/plot_2d.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"2-dimensional plots — plot_2d","text":"plot","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/plot_2d.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"2-dimensional plots — plot_2d","text":"function plots clusters using 2-dimensional data medoids centroids.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/plot_2d.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"2-dimensional plots — plot_2d","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/plot_2d.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"2-dimensional plots — plot_2d","text":"","code":"# data(dietary_survey_IBS)  # dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]  # dat = center_scale(dat)  # pca_dat = stats::princomp(dat)$scores[, 1:2]  # km = KMeans_rcpp(pca_dat, clusters = 2, num_init = 5, max_iters = 100)  # plot_2d(pca_dat, km$clusters, km$centroids)"},{"path":"https://mlampros.github.io/ClusterR/reference/predict_GMM.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction function for a Gaussian Mixture Model object — predict_GMM","title":"Prediction function for a Gaussian Mixture Model object — predict_GMM","text":"Prediction function Gaussian Mixture Model object","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_GMM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction function for a Gaussian Mixture Model object — predict_GMM","text":"","code":"predict_GMM(data, CENTROIDS, COVARIANCE, WEIGHTS)  # S3 method for class 'GMMCluster' predict(object, newdata, ...)"},{"path":"https://mlampros.github.io/ClusterR/reference/predict_GMM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction function for a Gaussian Mixture Model object — predict_GMM","text":"data matrix data frame CENTROIDS matrix data frame containing centroids (means), stored row vectors COVARIANCE matrix data frame (diagonal covariance) 3D array (full covariance matrices) WEIGHTS vector containing weights object, newdata, ... arguments `predict` generic","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_GMM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction function for a Gaussian Mixture Model object — predict_GMM","text":"list consisting log-likelihoods, cluster probabilities cluster labels.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_GMM.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prediction function for a Gaussian Mixture Model object — predict_GMM","text":"function takes centroids, covariance matrix weights trained model returns log-likelihoods, cluster probabilities cluster labels new data. function handles diagonal covariance matrices (2D matrix) full covariance matrices (3D array/cube).","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_GMM.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prediction function for a Gaussian Mixture Model object — predict_GMM","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_GMM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prediction function for a Gaussian Mixture Model object — predict_GMM","text":"","code":"data(dietary_survey_IBS)  dat = as.matrix(dietary_survey_IBS[, -ncol(dietary_survey_IBS)])  dat = center_scale(dat)  gmm = GMM(dat, 2, \"maha_dist\", \"random_subset\", 10, 10)  # pr = predict_GMM(dat, gmm$centroids, gmm$covariance_matrices, gmm$weights)"},{"path":"https://mlampros.github.io/ClusterR/reference/predict_KMeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction function for the k-means — predict_KMeans","title":"Prediction function for the k-means — predict_KMeans","text":"Prediction function k-means","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_KMeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction function for the k-means — predict_KMeans","text":"","code":"predict_KMeans(data, CENTROIDS, threads = 1, fuzzy = FALSE)  # S3 method for class 'KMeansCluster' predict(object, newdata, fuzzy = FALSE, threads = 1, ...)"},{"path":"https://mlampros.github.io/ClusterR/reference/predict_KMeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction function for the k-means — predict_KMeans","text":"data matrix data frame CENTROIDS matrix initial cluster centroids. rows CENTROIDS matrix equal number clusters columns equal columns data. threads integer specifying number cores run parallel fuzzy either TRUE FALSE. TRUE, probabilities cluster returned based distance observations centroids. object, newdata, ... arguments `predict` generic","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_KMeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction function for the k-means — predict_KMeans","text":"vector (clusters)","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_KMeans.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prediction function for the k-means — predict_KMeans","text":"function takes data output centroids returns clusters.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_KMeans.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prediction function for the k-means — predict_KMeans","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_KMeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prediction function for the k-means — predict_KMeans","text":"","code":"data(dietary_survey_IBS)  dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]  dat = center_scale(dat)  km = KMeans_rcpp(dat, clusters = 2, num_init = 5, max_iters = 100, initializer = 'kmeans++')  pr = predict_KMeans(dat, km$centroids, threads = 1)"},{"path":"https://mlampros.github.io/ClusterR/reference/predict_MBatchKMeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction function for Mini-Batch-k-means — predict_MBatchKMeans","title":"Prediction function for Mini-Batch-k-means — predict_MBatchKMeans","text":"Prediction function Mini-Batch-k-means","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_MBatchKMeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction function for Mini-Batch-k-means — predict_MBatchKMeans","text":"","code":"predict_MBatchKMeans(data, CENTROIDS, fuzzy = FALSE, updated_output = FALSE)  # S3 method for class 'MBatchKMeans' predict(object, newdata, fuzzy = FALSE, ...)"},{"path":"https://mlampros.github.io/ClusterR/reference/predict_MBatchKMeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction function for Mini-Batch-k-means — predict_MBatchKMeans","text":"data matrix data frame CENTROIDS matrix initial cluster centroids. rows CENTROIDS matrix equal number clusters columns equal columns data. fuzzy either TRUE FALSE. TRUE prediction probabilities calculated using distance observations centroids. updated_output either TRUE FALSE. TRUE 'predict_MBatchKMeans' function follow output object behaviour 'predict_KMeans' function (fuzzy TRUE return probabilities otherwise return hard clusters). parameter removed version 1.4.0 become default output format. object, newdata, ... arguments `predict` generic","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_MBatchKMeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction function for Mini-Batch-k-means — predict_MBatchKMeans","text":"fuzzy = TRUE function returns list two attributes: vector clusters matrix cluster probabilities. Otherwise, returns vector clusters.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_MBatchKMeans.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prediction function for Mini-Batch-k-means — predict_MBatchKMeans","text":"function takes data output centroids returns clusters.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_MBatchKMeans.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prediction function for Mini-Batch-k-means — predict_MBatchKMeans","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_MBatchKMeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prediction function for Mini-Batch-k-means — predict_MBatchKMeans","text":"","code":"data(dietary_survey_IBS)  dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]  dat = center_scale(dat)  MbatchKm = MiniBatchKmeans(dat, clusters = 2, batch_size = 20, num_init = 5, early_stop_iter = 10)  pr = predict_MBatchKMeans(dat, MbatchKm$centroids, fuzzy = FALSE) #> Warning: `predict_MBatchKMeans()` was deprecated in ClusterR 1.3.0. #> ℹ Beginning from version 1.4.0, if the fuzzy parameter is TRUE the function #>   'predict_MBatchKMeans' will return only the probabilities, whereas currently #>   it also returns the hard clusters"},{"path":"https://mlampros.github.io/ClusterR/reference/predict_Medoids.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions for the Medoid functions — predict_Medoids","title":"Predictions for the Medoid functions — predict_Medoids","text":"Predictions Medoid functions","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_Medoids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions for the Medoid functions — predict_Medoids","text":"","code":"predict_Medoids(   data,   MEDOIDS = NULL,   distance_metric = \"euclidean\",   fuzzy = FALSE,   minkowski_p = 1,   threads = 1 )  # S3 method for class 'MedoidsCluster' predict(object, newdata, fuzzy = FALSE, threads = 1, ...)"},{"path":"https://mlampros.github.io/ClusterR/reference/predict_Medoids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions for the Medoid functions — predict_Medoids","text":"data matrix data frame MEDOIDS matrix initial cluster medoids (data observations). rows MEDOIDS matrix equal number clusters columns MEDOIDS matrix equal columns data. distance_metric string specifying distance method. One ,  euclidean,  manhattan,  chebyshev,  canberra,  braycurtis,  pearson_correlation,  simple_matching_coefficient,  minkowski,  hamming,  jaccard_coefficient,  Rao_coefficient,  mahalanobis, cosine fuzzy either TRUE FALSE. TRUE, probabilities cluster returned based distance observations medoids. minkowski_p numeric value specifying minkowski parameter case distance_metric = \"minkowski\" threads integer specifying number cores run parallel. Openmp utilized parallelize number initializations (num_init) object, newdata, ... arguments `predict` generic","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_Medoids.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions for the Medoid functions — predict_Medoids","text":"list following attributes returned : clusters, fuzzy_clusters (fuzzy = TRUE), dissimilarity.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_Medoids.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Predictions for the Medoid functions — predict_Medoids","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/predict_Medoids.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictions for the Medoid functions — predict_Medoids","text":"","code":"data(dietary_survey_IBS)  dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)]  dat = center_scale(dat)  cm = Cluster_Medoids(dat, clusters = 3, distance_metric = 'euclidean', swap_phase = TRUE)  pm = predict_Medoids(dat, MEDOIDS = cm$medoids, 'euclidean', fuzzy = TRUE)"},{"path":"https://mlampros.github.io/ClusterR/reference/silhouette_of_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Silhouette width based on pre-computed clusters — silhouette_of_clusters","title":"Silhouette width based on pre-computed clusters — silhouette_of_clusters","text":"Silhouette width based pre-computed clusters","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/silhouette_of_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Silhouette width based on pre-computed clusters — silhouette_of_clusters","text":"","code":"silhouette_of_clusters(data, clusters)"},{"path":"https://mlampros.github.io/ClusterR/reference/silhouette_of_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Silhouette width based on pre-computed clusters — silhouette_of_clusters","text":"data matrix data frame clusters numeric vector corresponds pre-computed clusters (see example section details). size 'clusters' vector must equal number rows input data","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/silhouette_of_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Silhouette width based on pre-computed clusters — silhouette_of_clusters","text":"list object first sublist 'silhouette summary', second sublist 'silhouette matrix' third sublist 'global average silhouette' (based silhouette values observations)","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/silhouette_of_clusters.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Silhouette width based on pre-computed clusters — silhouette_of_clusters","text":"Lampros Mouselimis","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/silhouette_of_clusters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Silhouette width based on pre-computed clusters — silhouette_of_clusters","text":"","code":"data(dietary_survey_IBS) dat = dietary_survey_IBS[, -ncol(dietary_survey_IBS)] dat = center_scale(dat)  clusters = 2  # compute k-means km = KMeans_rcpp(dat, clusters = clusters, num_init = 5, max_iters = 100, initializer = 'kmeans++')  # compute the silhouette width silh_km = silhouette_of_clusters(data = dat, clusters = km$clusters)  # silhouette summary silh_summary = silh_km$silhouette_summary  # silhouette matrix (including cluster & dissimilarity) silh_mtrx = silh_km$silhouette_matrix  # global average silhouette glob_avg = silh_km$silhouette_global_average"},{"path":"https://mlampros.github.io/ClusterR/reference/soybean.html","id":null,"dir":"Reference","previous_headings":"","what":"The soybean (large) data set from the UCI repository — soybean","title":"The soybean (large) data set from the UCI repository — soybean","text":"19 classes, first 15 used prior work. folklore seems last four classes unjustified data since examples. 35 categorical attributes, nominal ordered. value 'dna' means apply. values attributes encoded numerically, first value encoded '0', second '1', forth. Unknown values imputated using mice package.","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/soybean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The soybean (large) data set from the UCI repository — soybean","text":"","code":"data(soybean)"},{"path":"https://mlampros.github.io/ClusterR/reference/soybean.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The soybean (large) data set from the UCI repository — soybean","text":"data frame 307 Instances 36 attributes (including class attribute, \"class\")","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/soybean.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The soybean (large) data set from the UCI repository — soybean","text":"column names data (including class) appear following order: date, plant-stand, precip, temp, hail, crop-hist, area-damaged, severity, seed-tmt, germination, plant-growth, leaves, leafspots-halo, leafspots-marg, leafspot-size, leaf-shread, leaf-malf, leaf-mild, stem, lodging, stem-cankers, canker-lesion, fruiting-bodies, external decay, mycelium, int-discolor, sclerotia, fruit-pods, fruit spots, seed, mold-growth, seed-discolor, seed-size, shriveling, roots, class","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/soybean.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The soybean (large) data set from the UCI repository — soybean","text":"R.S. Michalski R.L. Chilausky, Learning Told Learning Examples: Experimental Comparison Two Methods Knowledge Acquisition Context Developing Expert System Soybean Disease Diagnosis, International Journal Policy Analysis Information Systems, Vol. 4, . 2, 1980. Donor: Ming Tan & Jeff Schlimmer (Jeff.Schlimmer cs.cmu.edu) download source: https://archive.ics.uci.edu/ml/datasets/Soybean+(Large)","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/soybean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The soybean (large) data set from the UCI repository — soybean","text":"","code":"data(soybean)  X = soybean[, -ncol(soybean)]  y = soybean[, ncol(soybean)]"},{"path":"https://mlampros.github.io/ClusterR/reference/tryCatch_GMM.html","id":null,"dir":"Reference","previous_headings":"","what":"tryCatch function to prevent armadillo errors — tryCatch_GMM","title":"tryCatch function to prevent armadillo errors — tryCatch_GMM","text":"tryCatch function prevent armadillo errors","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/tryCatch_GMM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"tryCatch function to prevent armadillo errors — tryCatch_GMM","text":"","code":"tryCatch_GMM(   data,   gaussian_comps,   dist_mode,   seed_mode,   km_iter,   em_iter,   verbose,   var_floor,   seed,   full_covariance_matrices )"},{"path":"https://mlampros.github.io/ClusterR/reference/tryCatch_KMEANS_arma.html","id":null,"dir":"Reference","previous_headings":"","what":"tryCatch function to prevent armadillo errors in KMEANS_arma — tryCatch_KMEANS_arma","title":"tryCatch function to prevent armadillo errors in KMEANS_arma — tryCatch_KMEANS_arma","text":"tryCatch function prevent armadillo errors KMEANS_arma","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/tryCatch_KMEANS_arma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"tryCatch function to prevent armadillo errors in KMEANS_arma — tryCatch_KMEANS_arma","text":"","code":"tryCatch_KMEANS_arma(   data,   clusters,   n_iter,   verbose,   seed_mode,   CENTROIDS,   seed )"},{"path":"https://mlampros.github.io/ClusterR/reference/tryCatch_optimal_clust_GMM.html","id":null,"dir":"Reference","previous_headings":"","what":"tryCatch function to prevent armadillo errors in GMM_arma_AIC_BIC — tryCatch_optimal_clust_GMM","title":"tryCatch function to prevent armadillo errors in GMM_arma_AIC_BIC — tryCatch_optimal_clust_GMM","text":"tryCatch function prevent armadillo errors GMM_arma_AIC_BIC","code":""},{"path":"https://mlampros.github.io/ClusterR/reference/tryCatch_optimal_clust_GMM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"tryCatch function to prevent armadillo errors in GMM_arma_AIC_BIC — tryCatch_optimal_clust_GMM","text":"","code":"tryCatch_optimal_clust_GMM(   data,   max_clusters,   dist_mode,   seed_mode,   km_iter,   em_iter,   verbose,   var_floor,   criterion,   seed )"},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-135","dir":"Changelog","previous_headings":"","what":"ClusterR 1.3.5","title":"ClusterR 1.3.5","text":"removed SystemRequirements DESCRIPTION file.","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-134","dir":"Changelog","previous_headings":"","what":"ClusterR 1.3.4","title":"ClusterR 1.3.4","text":"CRAN release: 2025-09-14 updated Makevars Makevars.win files adding -DARMA_USE_CURRENT (see issue: https://github.com/RcppCore/RcppArmadillo/issues/476) modified line 723 ClusterRHeader.h file !arma::is_finite(tmp_conv); !arma::(tmp_conv.is_finite()); modified line 1336 ClusterRHeader.h file !arma::is_finite(tmp_update_centroids); !arma::(tmp_update_centroids.is_finite()); replaced cases arma::is_finite(...) line 1845 line 2333 ClusterRHeader.h file std::isfinite(...) adjusted Authors@R field DESCRIPTION file due CRAN NOTE","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-133","dir":"Changelog","previous_headings":"","what":"ClusterR 1.3.3","title":"ClusterR 1.3.3","text":"CRAN release: 2024-06-18 fixed issue related R_NilValue ‘KMEANS_rcpp()’ Rcpp function src/export_inst_folder_headers.cpp file. mistakenly used input R_NilValue whereas used CENTROIDS argument (see issue: https://github.com/mlampros/ClusterR/issues/54)","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-132","dir":"Changelog","previous_headings":"","what":"ClusterR 1.3.2","title":"ClusterR 1.3.2","text":"CRAN release: 2023-12-04 /inst/include/affinity_propagation.h:474:37 476:58 removed -mthreads compilation option “Makevars.win” file","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-131","dir":"Changelog","previous_headings":"","what":"ClusterR 1.3.1","title":"ClusterR 1.3.1","text":"CRAN release: 2023-04-29 fixed mistake related potential warning ‘Optimal_Clusters_GMM()’ function (see issue: https://github.com/mlampros/ClusterR/issues/45) modified ‘GMM()’ function adding ‘full_covariance_matrices’ parameter (see issue: https://github.com/mlampros/ClusterR/issues/48) modified slightly ‘predict_medoids()’ function case ‘fuzzy’ parameter set TRUE modified ‘validate_centroids()’ Rcpp function ‘predict_KMeans()’ R function now take also ‘fuzzy’ ‘eps’ parameters (latter included Rcpp function). added tests cases. added ‘predict()’ function mini-batch-kmeans removed “CXX_STD = CXX11” “Makevars” files, “[[Rcpp::plugins(cpp11)]]” “export_inst_folder_headers.cpp” file due following NOTE CRAN, “NOTE Specified C++11: please drop specification unless essential” (see also: https://www.tidyverse.org/blog/2023/03/cran-checks-compiled-code/#note-regarding-systemrequirements-c11) added deprecation warning ‘predict_MBatchKMeans()’ function starting version 1.4.0, ‘fuzzy’ parameter TRUE function return probabilities, whereas currently also returns hard clusters. Moreover, added ‘updated_output’ parameter shows new output format set TRUE.","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-130","dir":"Changelog","previous_headings":"","what":"ClusterR 1.3.0","title":"ClusterR 1.3.0","text":"CRAN release: 2023-01-21 updated documentation ‘Optimal_Clusters_KMeans()’ function related ‘silhouette’ metric (see issue: https://github.com/mlampros/ClusterR/issues/42) added R ‘silhouette_of_clusters()’ Rcpp ‘silhouette_clusters()’ functions return clusters, intra_cluster_dissimilarity silhouette width pre-computed clusters added test case R ‘silhouette_of_clusters()’ function ‘test-kmeans.R’ file modified ‘Optimal_Clusters_KMeans()’ function case criterion set “silhouette” (see issue: https://github.com/mlampros/ClusterR/issues/42) added ‘PERMUTATIONS_2D()’ Rcpp function replaces call Rcpp::Environment gtools(“package:gtools”) removed gtools R package dependency ClusterR package","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-129","dir":"Changelog","previous_headings":"","what":"ClusterR 1.2.9","title":"ClusterR 1.2.9","text":"CRAN release: 2022-12-13 pull request #41 removed class ‘Gaussian Mixture Models’ ‘Optimal_Clusters_GMM()’ function adjusted tests related ‘Optimal_Clusters_GMM()’ function errors raised (see issue: https://github.com/mlampros/ClusterR/issues/40)","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-128","dir":"Changelog","previous_headings":"","what":"ClusterR 1.2.8","title":"ClusterR 1.2.8","text":"CRAN release: 2022-12-03 added cost_clusters_from_dissim_medoids() function added alternative ‘build’ phase Rcpp function corresponds exact algorithm comparison purposes (see function ‘updated_BUILD()’ ‘inst/include/ClusterRHeader.h’ file). didn’t see differences compared existing ‘build’ phase ‘Cluster_Medoids()’ function. updated documentation ‘Cluster_Medoids()’ function mentioning approximate exact ‘partition around medoids’ function","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-127","dir":"Changelog","previous_headings":"","what":"ClusterR 1.2.7","title":"ClusterR 1.2.7","text":"CRAN release: 2022-09-21 updated references weblink Optimal_Clusters_KMeans() function (github issue: https://github.com/mlampros/ClusterR/issues/27) added deprecation warning ‘seed’ parameter ‘Cluster_Medoids()’ function (github issue: https://github.com/mlampros/ClusterR/issues/33). parameter removed version ‘1.4.0’ replaced ‘ARMA_DONT_PRINT_ERRORS’ top ‘/src/export_inst_folder_headers.cpp’ file ‘ARMA_WARN_LEVEL 0’ support ‘ARMA_DONT_PRINT_ERRORS’ removed fixed bug ‘ClaraMedoids()’ Rcpp function (/inst/ClusterRHeader.h file) related ‘seed’ parameter (github issue: https://github.com/mlampros/ClusterR/issues/35)","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-126","dir":"Changelog","previous_headings":"","what":"ClusterR 1.2.6","title":"ClusterR 1.2.6","text":"CRAN release: 2022-01-27 #24 Add S3 classes ClusteR objects (KMeansCluster, MedoidsCluster GMMCluster) add generic predict() print() methods. fixed issue related duplicated centroids internal kmeans_pp_init() function (see Github issue: https://github.com/mlampros/ClusterR/issues/25) added test case check duplicated centroids related kmeans_pp_init() function","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-125","dir":"Changelog","previous_headings":"","what":"ClusterR 1.2.5","title":"ClusterR 1.2.5","text":"CRAN release: 2021-05-21 fixed Error CRAN results due mistakes creation matrix test-kmeans.R file","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-124","dir":"Changelog","previous_headings":"","what":"ClusterR 1.2.4","title":"ClusterR 1.2.4","text":"CRAN release: 2021-05-04 fixed error CITATION file","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-123","dir":"Changelog","previous_headings":"","what":"ClusterR 1.2.3","title":"ClusterR 1.2.3","text":"CRAN release: 2021-05-03 ’ve added value 1 output clusters predict_GMM() function account difference indexing R C++ ’ve added CITATION file inst directory listing papers software used ClusterR package","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-122","dir":"Changelog","previous_headings":"","what":"ClusterR 1.2.2","title":"ClusterR 1.2.2","text":"CRAN release: 2020-05-12 ’ve added vectorized version clusters output Affinity Propagation algorithm ’ve added threads parameter predict_KMeans() function return k-means clusters parallel (useful especially high dimensional data, see: https://stackoverflow.com/q/61551071/8302386) ’ve added check-duplicated CENTROIDS -condition predict_KMeans() function similar base kmeans function (see: https://stackoverflow.com/q/61551071/8302386). Due fact CENTROIDS output matrix class “k-means clustering” base R function duplicated() performs check column-wise rather row-wise. Therefore checking duplicates set class NULL.","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-121","dir":"Changelog","previous_headings":"","what":"ClusterR 1.2.1","title":"ClusterR 1.2.1","text":"CRAN release: 2019-11-29 added dockerfile root package directory instructions README.md file build run docker image (https://github.com/mlampros/ClusterR/issues/17) fixed documentation Vignette mistake regarding KMeans_rcpp function (https://github.com/mlampros/ClusterR/issues/19) fixed “failure: condition length > 1” CRAN error appeared mainly due misuse base class() function multiple code snippets package (info matter see: https://developer.r-project.org/Blog/public/2019/11/09/--think-class.-think-/index.html)","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-120","dir":"Changelog","previous_headings":"","what":"ClusterR 1.2.0","title":"ClusterR 1.2.0","text":"CRAN release: 2019-07-18 added ‘cosine’ distance following functions: ‘Cluster_Medoids’, ‘Clara_Medoids’, ‘predict_Medoids’, ‘Optimal_Clusters_Medoids’ ‘distance_matrix’. fixed error case .pdf manual package (https://github.com/mlampros/ClusterR/issues/16)","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-119","dir":"Changelog","previous_headings":"","what":"ClusterR 1.1.9","title":"ClusterR 1.1.9","text":"CRAN release: 2019-04-14 added parallelization exact method AP_preferenceRange function computationally intensive bound method modified Optimal_Clusters_KMeans, Optimal_Clusters_GMM Optimal_Clusters_Medoids accept also contiguous non-contiguous vector besides single values max_clusters parameter. However, limitation currently user won’t place plot clusters receive ouput data ( can changed future however plotting function contiguous non-contiguous vectors must separate plotting function outside existing one). Moreover, distortion_fK criterion can’t computed Optimal_Clusters_KMeans function max_clusters parameter contiguous non-continguous vector ( distortion_fK criterion requires consecutive clusters ). applies also Adjusted_Rsquared criterion returns incorrect output. feature request see following Github issue.","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-118","dir":"Changelog","previous_headings":"","what":"ClusterR 1.1.8","title":"ClusterR 1.1.8","text":"CRAN release: 2019-01-11 moved OpenImageR dependency DESCRIPTION file ‘Imports’ ‘Suggests’, appears Vignette file.","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-117","dir":"Changelog","previous_headings":"","what":"ClusterR 1.1.7","title":"ClusterR 1.1.7","text":"CRAN release: 2018-12-09 fixed clang-UBSAN errors","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-116","dir":"Changelog","previous_headings":"","what":"ClusterR 1.1.6","title":"ClusterR 1.1.6","text":"CRAN release: 2018-11-08 updated README.md file (removed unnecessary calls ClusterR DESCRIPTION NAMESPACE files) renamed export_inst_header.cpp file src folder export_inst_folder_headers.cpp modified Predict_mini_batch_kmeans() function accept armadillo matrix rather Rcpp Numeric matrix. function appers ClusterRHeader.h file ( ‘inst’ folder ) export_inst_folder_headers.cpp file ( ‘src’ folder ) added mini_batch_params parameter Optimal_Clusters_KMeans function. Now, optimal number clusters can found also based min-batch-kmeans algorithm (except variance_explained criterion) changed license MIT GPL-3 added affinity propagation algorithm (www.psi.toronto.edu/index.php?q=affinity%20propagation). Especially, converted matlab files apcluster.m referenceRange.m. modified minimum version RcppArmadillo DESCRIPTION file 0.9.1 Affinity Propagation algorithm requires .is_symmetric() function, included version 0.9.1","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-115","dir":"Changelog","previous_headings":"","what":"ClusterR 1.1.5","title":"ClusterR 1.1.5","text":"CRAN release: 2018-10-05 version 1.1.5 ClusterR functions can take tibble objects input .","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-114","dir":"Changelog","previous_headings":"","what":"ClusterR 1.1.4","title":"ClusterR 1.1.4","text":"CRAN release: 2018-08-22 modified ClusterR package cpp-header-package allow linking cpp code Rcpp packages. See update README.md file (16-08-2018) information.","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-113","dir":"Changelog","previous_headings":"","what":"ClusterR 1.1.3","title":"ClusterR 1.1.3","text":"CRAN release: 2018-07-21 updated example section documentation replacing optimal_init kmeans++ initializer","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-112","dir":"Changelog","previous_headings":"","what":"ClusterR 1.1.2","title":"ClusterR 1.1.2","text":"CRAN release: 2018-05-03 fixed Issue related NAs produced integer overflow external_validation function. See, commented line Clustering_functions.R file (line 1830).","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-111","dir":"Changelog","previous_headings":"","what":"ClusterR 1.1.1","title":"ClusterR 1.1.1","text":"CRAN release: 2018-02-26 added tryCatch Optimal_Clusters_Medoids() function account error described Error Optimal_Clusters_Medoids function#5 issue","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-110","dir":"Changelog","previous_headings":"","what":"ClusterR 1.1.0","title":"ClusterR 1.1.0","text":"CRAN release: 2018-01-17 added DARMA_64BIT_WORD flag Makevars file allow package processing big datasets modified kmeans_miniBatchKmeans_GMM_Medoids.cpp file especially Rcpp::List::create() objects addrress clang-ASAN errors.","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-109","dir":"Changelog","previous_headings":"","what":"ClusterR 1.0.9","title":"ClusterR 1.0.9","text":"CRAN release: 2017-11-30 modified Optimal_Clusters_KMeans function return vector distortion_fK values criterion distortion_fK (instead WCSSE values). added ‘Moore-Penrose pseudo-inverse’ case ‘mahalanobis’ distance calculation.","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-108","dir":"Changelog","previous_headings":"","what":"ClusterR 1.0.8","title":"ClusterR 1.0.8","text":"CRAN release: 2017-10-28 modified OpenMP clauses .cpp files address ASAN errors. removed threads parameter KMeans_rcpp function, address ASAN errors ( negligible performance difference threaded non-threaded version especially num_init parameter less 10 ). threads parameter removed also Optimal_Clusters_KMeans function utilizes KMeans_rcpp function find optimal clusters various methods.","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-107","dir":"Changelog","previous_headings":"","what":"ClusterR 1.0.7","title":"ClusterR 1.0.7","text":"CRAN release: 2017-10-13 modified kmeans_miniBatchKmeans_GMM_Medoids.cpp file following lines order fix clang-ASAN errors (without loss performance): lines 1156-1160 : commented second OpenMp parallel-loop replaced k variable variable second -loop [dissim_mat() function] lines 1739-1741 : commented second OpenMp parallel-loop [silhouette_matrix() function] replaced () silhouette_matrix (arma::mat) variable names Silhouette_matrix, name overlapped name Rcpp function [silhouette_matrix function] replaced sorted_medoids.n_elem variable unsigned int sorted_medoids_elem [silhouette_matrix function] modified following functions clustering_functions.R file: KMeans_rcpp() : added experimental note details optimal_init quantile_init initializers. Optimal_Clusters_KMeans() : added experimental note details optimal_init quantile_init initializers. MiniBatchKmeans() : added experimental note details optimal_init quantile_init initializers.","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-106","dir":"Changelog","previous_headings":"","what":"ClusterR 1.0.6","title":"ClusterR 1.0.6","text":"CRAN release: 2017-08-03 normalized variation information added external_validation function (https://github.com/mlampros/ClusterR/pull/1)","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-105","dir":"Changelog","previous_headings":"","what":"ClusterR 1.0.5","title":"ClusterR 1.0.5","text":"CRAN release: 2017-02-11 fixed valgrind memory errors","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-104","dir":"Changelog","previous_headings":"","what":"ClusterR 1.0.4","title":"ClusterR 1.0.4","text":"CRAN release: 2017-02-02 removed warnings, occured compilation. corrected UBSAN memory errors occured due mistake check_medoids() function utils_rcpp.cpp file. also modified quantile_init_rcpp() function utils_rcpp.cpp file print warning duplicates present initial centroid matrix.","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-103","dir":"Changelog","previous_headings":"","what":"ClusterR 1.0.3","title":"ClusterR 1.0.3","text":"CRAN release: 2016-10-08 updated dissimilarity functions accept data missing values. added error exception predict_GMM() function case determinant equal zero. latter possible data includes highly correlated variables variables low variance. replaced unsigned int’s rcpp files int data types","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-102","dir":"Changelog","previous_headings":"","what":"ClusterR 1.0.2","title":"ClusterR 1.0.2","text":"modified RcppArmadillo functions ClusterR passes Windows OSX OS package check results","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-101","dir":"Changelog","previous_headings":"","what":"ClusterR 1.0.1","title":"ClusterR 1.0.1","text":"CRAN release: 2016-09-09 modified RcppArmadillo functions ClusterR passes Windows OSX OS package check results","code":""},{"path":"https://mlampros.github.io/ClusterR/news/index.html","id":"clusterr-100","dir":"Changelog","previous_headings":"","what":"ClusterR 1.0.0","title":"ClusterR 1.0.0","text":"CRAN release: 2016-09-06","code":""}]
